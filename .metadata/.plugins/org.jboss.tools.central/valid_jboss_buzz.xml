<?xml version="1.0" encoding="UTF-8"?>
<feed xmlns="http://www.w3.org/2005/Atom" xmlns:dc="http://purl.org/dc/elements/1.1/"><title>JBoss Tools Aggregated Feed</title><link rel="alternate" href="http://tools.jboss.org" /><subtitle>JBoss Tools Aggregated Feed</subtitle><dc:creator>JBoss Tools</dc:creator><entry><title>Kubernetes-native inner loop development with Quarkus</title><link rel="alternate" href="https://developers.redhat.com/articles/2022/12/12/kubernetes-native-inner-loop-development-quarkus" /><author><name>Eric Deandrea</name></author><id>61ab4bf3-0be1-494b-8c0d-451db908fb92</id><updated>2022-12-12T07:00:00Z</updated><published>2022-12-12T07:00:00Z</published><summary type="html">&lt;p&gt;&lt;a href="https://developers.redhat.com/topics/microservices"&gt;Microservices&lt;/a&gt; today are often deployed on a platform such as &lt;a href="https://developers.redhat.com/topics/kubernetes"&gt;Kubernetes&lt;/a&gt;, which orchestrates the deployment and management of containerized applications. Microservices, however, don't exist in a vacuum. They typically communicate with other services, such as databases, message brokers, or other microservices. Therefore, an application usually consists of multiple services that form a complete solution.&lt;/p&gt; &lt;p&gt;But, as a developer, how do you develop and test an individual microservice that is part of a larger system? This article examines some common &lt;em&gt;inner-loop&lt;/em&gt; development cycle challenges and shows how Quarkus and other technologies help solve some of these challenges.&lt;/p&gt; &lt;h2&gt;What is the inner loop?&lt;/h2&gt; &lt;p&gt;Almost all software development is iterative. T&lt;span&gt;he &lt;em&gt;inner loop&lt;/em&gt; contains everything that happens on a developer's machine &lt;/span&gt;&lt;em&gt;before&lt;/em&gt;&lt;span&gt; committing code into version control. The inner loop is where a developer writes code, builds and tests it, and perhaps runs the code locally. In today's world, the inner loop could also include multiple commits to a &lt;/span&gt;&lt;a href="https://docs.github.com/en/pull-requests/collaborating-with-pull-requests/proposing-changes-to-your-work-with-pull-requests/about-pull-requests"&gt;Git pull request&lt;/a&gt;&lt;span&gt;, where a developer may commit multiple times against a specific feature until that feature is deemed complete.&lt;/span&gt;&lt;/p&gt; &lt;p class="Indent1"&gt;&lt;strong&gt;Note:&lt;/strong&gt; The word &lt;em&gt;local&lt;/em&gt; is also up for debate in industry today as more and more remote development environments, such as &lt;a href="https://developers.redhat.com/developer-sandbox/ide"&gt;Red Hat OpenShift Dev Spaces&lt;/a&gt;, &lt;a href="https://gitpod.io"&gt;Gitpod&lt;/a&gt;, and &lt;a href="https://github.com/features/codespaces"&gt;GitHub Codespaces&lt;/a&gt; are available. This article does not differentiate between a developer machine and any of these kinds of environments. They are all viewed as &lt;em&gt;local&lt;/em&gt; in this article.&lt;/p&gt; &lt;p&gt;&lt;em&gt;Inner loop&lt;/em&gt; shifts to &lt;em&gt;outer loop&lt;/em&gt; when code reaches a point in source control where it needs to be built, tested, scanned, and ultimately deployed by automated &lt;a href="https://developers.redhat.com/topics/ci-cd"&gt;continuous integration and deployment&lt;/a&gt; (CI/CD) processes. Figure 1 illustrates a simple inner loop and outer loop.&lt;/p&gt; &lt;div class="rhd-c-figure"&gt; &lt;article class="align-center media media--type-image media--view-mode-article-content"&gt;&lt;div class="field field--name-image field--type-image field--label-hidden field__items"&gt; &lt;a href="https://developers.redhat.com/sites/default/files/fig1_24.png" data-featherlight="image"&gt;&lt;img loading="lazy" src="https://developers.redhat.com/sites/default/files/styles/article_floated/public/fig1_24.png?itok=LsPqCLBm" width="600" height="320" alt="Diagram showing that the inner loop takes place on a developer's local machine, whereas the outer loop takes place within CI/CD processes." typeof="Image" /&gt;&lt;/a&gt; &lt;/div&gt; &lt;div class="field field--name-field-caption field--type-string field--label-hidden field__items"&gt; &lt;div class="rhd-c-caption field__item"&gt; Figure 1: The inner loop takes place on a developer's local machine, whereas the outer loop takes place within CI/CD processes. &lt;/div&gt; &lt;/div&gt; &lt;/article&gt;&lt;/div&gt; &lt;h2&gt;Challenges of inner loop development&lt;/h2&gt; &lt;p&gt;Developing a single microservice in isolation is challenging enough without worrying about additional downstream services. How do you run a microservice in isolation on your local machine if it depends on other services for it to function properly?&lt;/p&gt; &lt;p&gt;Using various mocking techniques, you can to some extent get around the absence of required services when writing and running tests. Mocking techniques generally work great for testing. You can also use in-memory replacements for required services, such as an &lt;a href="https://www.h2database.com"&gt;H2 database&lt;/a&gt; instead of a separate database instance. Beyond that, if you want or need to run the application locally, you need a better solution.&lt;/p&gt; &lt;p&gt;Of course, you could &lt;em&gt;try&lt;/em&gt; to reproduce your application's entire environment on your development machine. But even if you could, would you really want to? Do you think a developer at Twitter or Netflix could reproduce their environment on their development machine? Figure 2 shows the complexity of their architectures. &lt;a href="https://eng.lyft.com/scaling-productivity-on-microservices-at-lyft-part-1-a2f5d9a77813"&gt;Lyft also tried this approach&lt;/a&gt; and found it wasn't feasible or scalable.&lt;/p&gt; &lt;div class="rhd-c-figure"&gt; &lt;article class="align-center media media--type-image media--view-mode-article-content"&gt;&lt;div class="field field--name-image field--type-image field--label-hidden field__items"&gt; &lt;a href="https://developers.redhat.com/sites/default/files/fig2.jpeg" data-featherlight="image"&gt;&lt;img loading="lazy" src="https://developers.redhat.com/sites/default/files/styles/article_floated/public/fig2.jpeg?itok=a2zAHnqd" width="600" height="264" alt="Diagram illustrating that major services such as Netflix and Twitter can easy have more than 500 microservices." typeof="Image" /&gt;&lt;/a&gt; &lt;/div&gt; &lt;span class="field field--name-field-source-url field--type-string field--label-hidden field__items"&gt; https://future.com/the-case-for-developer-experience &lt;/span&gt; &lt;div class="field field--name-field-caption field--type-string field--label-hidden field__items"&gt; &lt;div class="rhd-c-caption field__item"&gt; Figure 2: Major services such as Netflix and Twitter can easy have more than 500 microservices. &lt;/div&gt; &lt;/div&gt; &lt;/article&gt;&lt;/div&gt; &lt;h2&gt;Container-based inner loop solutions&lt;/h2&gt; &lt;p&gt;Using containers can help speed up and improve the inner loop development lifecycle. Containers can help isolate and provide a local instance of a dependent service. We'll look at a few popular tools and technologies for the inner loop.&lt;/p&gt; &lt;h3&gt;Docker Compose&lt;/h3&gt; &lt;p&gt;One common pattern is to use &lt;a href="https://docs.docker.com/compose"&gt;Docker Compose&lt;/a&gt; to run some of your microservice's dependent services (databases, message brokers, etc.) locally while you run, debug, and test your microservice. With Docker Compose, you define a set of containerized services that provide the capabilities required by your microservice. You can easily start, stop, and view logs from these containerized services.&lt;/p&gt; &lt;p&gt;However, there are a few downsides to using Docker Compose. First, you must maintain your Docker Compose configuration independently of your application's code. You must remember to make changes to the Docker Compose configuration as your application evolves, sometimes duplicating configuration between your application and your Docker Compose configuration.&lt;/p&gt; &lt;p&gt;Second, you are locked into using the Docker binary. For Windows and macOS users, &lt;a href="https://www.docker.com/pricing/faq"&gt;Docker Desktop is no longer free for many non-individual users&lt;/a&gt;. You are also prevented from using other container runtimes, such as &lt;a href="https://podman.io"&gt;Podman&lt;/a&gt;. &lt;a href="https://www.redhat.com/sysadmin/podman-docker-compose"&gt;Podman does support Docker Compose&lt;/a&gt;, but it doesn't support everything you can do with Docker Compose, especially on non-Linux machines.&lt;/p&gt; &lt;h3&gt;Testcontainers&lt;/h3&gt; &lt;p&gt;&lt;a href="https://www.testcontainers.org"&gt;Testcontainers&lt;/a&gt; is an excellent library for creating and managing container instances for various services when applications run tests. It provides lightweight, throwaway instances of common databases, message brokers, or anything else that can run in a container.&lt;/p&gt; &lt;p&gt;But Testcontainers is only a library. That means an application must incorporate it and &lt;em&gt;do&lt;/em&gt; something with it to realize its benefits. Generally speaking, applications that use Testcontainers do so when executing unit or integration tests, but not in production. A developer generally won't include the library in the application's dependencies because Testcontainers doesn't belong as a dependency when the application is deployed into a &lt;em&gt;real&lt;/em&gt; environment with &lt;em&gt;real&lt;/em&gt; services.&lt;/p&gt; &lt;h3&gt;Quarkus&lt;/h3&gt; &lt;p&gt;&lt;a href="https://developers.redhat.com/products/quarkus"&gt;Quarkus&lt;/a&gt; is a Kubernetes-native Java application framework focusing on more than just feature sets. In addition to enabling fast startup times and low memory footprints compared to traditional Java applications, Quarkus ensures that every feature works well, with little to no configuration, in a highly intuitive way. The framework aims to make it trivial to develop simple things and easy to develop more complex ones. Beyond simply working well, Quarkus aims to bring &lt;a href="https://quarkus.io/developer-joy"&gt;Developer Joy&lt;/a&gt;, specifically targeting the inner loop development lifecycle.&lt;/p&gt; &lt;h4&gt;Dev mode&lt;/h4&gt; &lt;p&gt;The first part of the Quarkus Developer Joy story, live coding via &lt;a href="https://quarkus.io/guides/maven-tooling#dev-mode"&gt;Quarkus dev mode&lt;/a&gt;, improves and expedites the inner loop development process. When Quarkus dev mode starts, Quarkus automatically reflects code changes within the running application. Therefore, Quarkus combines the &lt;strong&gt;Write Code&lt;/strong&gt;, &lt;strong&gt;Build&lt;/strong&gt;, and &lt;strong&gt;Deploy/Run&lt;/strong&gt; steps of Figure 1's inner loop into a single step. Simply write code, interact with your application, and see your changes running with little to no delay.&lt;/p&gt; &lt;h4&gt;Dev Services&lt;/h4&gt; &lt;p&gt;A second part of the Quarkus Developer Joy story, &lt;a href="https://quarkus.io/guides/dev-services"&gt;Quarkus Dev Services&lt;/a&gt;, automatically provisions and configures supporting services, such as databases, message brokers, and more. When you run Quarkus in dev mode or execute tests, Quarkus examines all the extensions present. Quarkus then automatically starts any unconfigured and relevant service and configures the application to use that service.&lt;/p&gt; &lt;p&gt;Quarkus Dev Services uses Testcontainers, which we've already discussed, but in a manner completely transparent to the developer. The developer does not need to add the Testcontainers libraries, perform any integration or configuration, or write any code. Furthermore, Dev Services does not affect the application when it is deployed into a real environment with real services.&lt;/p&gt; &lt;p&gt;Additionally, if you have multiple Quarkus applications on your local machine and run them in dev mode, by default, Dev Services attempts to share the services between the applications. Sharing services is beneficial if you work on more than one application that uses the same service, such as a message broker.&lt;/p&gt; &lt;p&gt;Let's use the &lt;a href="https://github.com/quarkusio/quarkus-super-heroes"&gt;Quarkus Superheroes sample application&lt;/a&gt; as an example. The application consists of several microservices that together form an extensive system. Some microservices communicate synchronously via REST. Others are event-driven, producing and consuming events to and from &lt;a href="https://kafka.apache.org"&gt;Apache Kafka&lt;/a&gt;. Some microservices are reactive, whereas others are traditional. All the microservices produce metrics consumed by &lt;a href="https://prometheus.io"&gt;Prometheus&lt;/a&gt; and export tracing information to &lt;a href="https://opentelemetry.io"&gt;OpenTelemetry&lt;/a&gt;.&lt;/p&gt; &lt;p&gt;The source code for the application is on &lt;a href="https://github.com/quarkusio/quarkus-super-heroes"&gt;GitHub&lt;/a&gt; under an Apache 2.0 license. The system's architecture is shown in Figure 3.&lt;/p&gt; &lt;figure class="align-center rhd-u-has-filter-caption" role="group"&gt;&lt;div class="rhd-c-figure"&gt; &lt;article class="media media--type-image media--view-mode-article-content"&gt;&lt;div class="field field--name-image field--type-image field--label-hidden field__items"&gt; &lt;a href="https://developers.redhat.com/sites/default/files/fig3_9.png" data-featherlight="image"&gt;&lt;img loading="lazy" src="https://developers.redhat.com/sites/default/files/styles/article_floated/public/fig3_9.png?itok=wilWXzNN" width="600" height="686" alt="Architectural diagram of the Superheroes application, which has many microservices, some with dependencies." typeof="Image" /&gt;&lt;/a&gt; &lt;/div&gt; &lt;div class="field field--name-field-caption field--type-string field--label-hidden field__items"&gt; &lt;div class="rhd-c-caption field__item"&gt; Figure 3: The Superheroes application has many microservices, some with dependencies. &lt;/div&gt; &lt;/div&gt; &lt;/article&gt;&lt;/div&gt; &lt;figcaption class="rhd-c-caption"&gt;Figure 3: The Quarkus Superheroes application has many microservices and additional dependent services.&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;In the Quarkus Superheroes sample application, you could start both the &lt;code&gt;rest-fights&lt;/code&gt; and &lt;code&gt;event-statistics&lt;/code&gt; services locally in dev mode. The &lt;code&gt;rest-fights&lt;/code&gt; dev mode starts a &lt;a href="https://www.mongodb.com"&gt;MongoDB&lt;/a&gt; container instance, an &lt;a href="https://www.apicur.io/registry"&gt;Apicurio Registry&lt;/a&gt; container instance, and an &lt;a href="https://kafka.apache.org"&gt;Apache Kafka&lt;/a&gt; container instance. The &lt;code&gt;event-statistics&lt;/code&gt; service also requires an Apicurio Registry instance and an Apache Kafka instance, so the instance started by the &lt;code&gt;rest-fights&lt;/code&gt; dev mode will be discovered and used by the &lt;code&gt;event-statistics&lt;/code&gt; service.&lt;/p&gt; &lt;h4&gt;Continuous testing&lt;/h4&gt; &lt;p&gt;A third part of the Quarkus Developer Joy story, &lt;a href="https://quarkus.io/guides/continuous-testing"&gt;continuous testing&lt;/a&gt;, provides instant feedback on code changes by immediately executing affected tests in the background. Quarkus detects which tests cover which code and reruns only the tests relevant to that code as you change it. Quarkus continuous testing combines testing with dev mode and Dev Services into a powerful inner loop productivity feature, shrinking all of Figure 1's inner loop lifecycle steps into a single step.&lt;/p&gt; &lt;h2&gt;Other inner loop solutions&lt;/h2&gt; &lt;p&gt;The solutions we've outlined thus far are extremely helpful with local inner loop development, especially if your microservice requires only a small set of other services, such as a database, or a database and message broker.&lt;/p&gt; &lt;p&gt;But when there are &lt;em&gt;lots&lt;/em&gt; of dependent services, trying to replicate them all on a local machine probably won't work well, if at all.&lt;/p&gt; &lt;p&gt;So what do you do? How do you get the speed and agility of inner loop development for an application when it depends on other services that you either &lt;em&gt;can't&lt;/em&gt; or &lt;em&gt;don't want to&lt;/em&gt; run locally?&lt;/p&gt; &lt;p&gt;One solution could be to manage an environment of &lt;em&gt;shared&lt;/em&gt; services. Each developer would then configure those services in their local setup, careful not to commit the configuration into source control.&lt;/p&gt; &lt;p&gt;Another solution could be to use Kubernetes, giving each developer a namespace where they can deploy what they need. The developer could then deploy the services and configure their local application to use them.&lt;/p&gt; &lt;p&gt;Both of these solutions &lt;em&gt;could&lt;/em&gt; work, but in reality, they usually end up with a problem: The microservice the developer is working on is &lt;em&gt;somewhere&lt;/em&gt; in the graph of services of an overall system. How does a developer trigger the microservice they care about to get called as part of a larger request or flow?&lt;/p&gt; &lt;p&gt;Wouldn't a better solution be to run the application locally, but make the larger system &lt;em&gt;think&lt;/em&gt; the application is actually deployed somewhere?&lt;/p&gt; &lt;p&gt;This kind of remote + local development model is becoming known as &lt;em&gt;remocal&lt;/em&gt;. It is an extremely powerful way to get immediate feedback during your inner loop development cycle while ensuring your application behaves properly in an environment that is close to or matches production.&lt;/p&gt; &lt;h3&gt;Quarkus remote development&lt;/h3&gt; &lt;p&gt;Another part of the Quarkus Developer Joy story, &lt;a href="https://quarkus.io/guides/maven-tooling#remote-development-mode"&gt;remote development&lt;/a&gt;, enables a developer to deploy an application into a remote environment and run Quarkus dev mode in that environment while doing live coding locally. Quarkus immediately synchronizes code changes to the remotely deployed instance.&lt;/p&gt; &lt;p&gt;Quarkus remote development allows a developer to develop the application in the same environment it will run in while having access to the same services it will have access to. Additionally, this capability greatly reduces the inner feedback loop while alleviating the "works on my machine" problem. Remote development also allows for quick and easy prototyping of new features and capabilities. Figure 4 illustrates how the remote development mode works.&lt;/p&gt; &lt;div class="rhd-c-figure"&gt; &lt;article class="align-center media media--type-image media--view-mode-article-content"&gt;&lt;div class="field field--name-image field--type-image field--label-hidden field__items"&gt; &lt;a href="https://developers.redhat.com/sites/default/files/dev_0.png" data-featherlight="image"&gt;&lt;img loading="lazy" src="https://developers.redhat.com/sites/default/files/styles/article_floated/public/dev_0.png?itok=68N800JI" width="600" height="353" alt="Quarkus remote dev mode incrementally synchronizes local code changes with a remote Quarkus application." typeof="Image" /&gt;&lt;/a&gt; &lt;/div&gt; &lt;div class="field field--name-field-caption field--type-string field--label-hidden field__items"&gt; &lt;div class="rhd-c-caption field__item"&gt; Figure 4: Quarkus remote dev mode incrementally synchronizes local code changes with a remote Quarkus application. &lt;/div&gt; &lt;/div&gt; &lt;/article&gt;&lt;/div&gt; &lt;p&gt;First, the application is deployed to Kubernetes, a virtual machine, a container, or just some Java virtual machine (JVM) somewhere. Once running, the developer runs the remote development mode on their local machine, connecting their local machine to the remote instance.&lt;/p&gt; &lt;p&gt;From there, development is just like live coding in Quarkus dev mode. As the developer makes code changes, Quarkus automatically compiles and pushes the changes to the remote instance.&lt;/p&gt; &lt;p&gt;Let's continue with the Quarkus Superheroes example from before. Let's assume the entire system is deployed into a Kubernetes cluster. Let's also assume you want to make changes to the &lt;code&gt;rest-fights&lt;/code&gt; microservice.&lt;/p&gt; &lt;p&gt;As shown in Figure 5, you start the &lt;code&gt;rest-fights&lt;/code&gt; microservice in remote dev mode on your local machine. The &lt;code&gt;rest-fights&lt;/code&gt; application running on the cluster connects to the MongoDB, Apicurio Registry, and Apache Kafka instances on the Kubernetes cluster.&lt;/p&gt; &lt;figure class="align-center rhd-u-has-filter-caption" role="group"&gt;&lt;div class="rhd-c-figure"&gt; &lt;article class="media media--type-image media--view-mode-article-content"&gt;&lt;div class="field field--name-image field--type-image field--label-hidden field__items"&gt; &lt;a href="https://developers.redhat.com/sites/default/files/fig5_7.png" data-featherlight="image"&gt;&lt;img loading="lazy" src="https://developers.redhat.com/sites/default/files/styles/article_floated/public/fig5_7.png?itok=fIwEDwZe" width="600" height="379" alt="Diagram showing changes to the local application during remote development send updates continuously to the services in the cloud." typeof="Image" /&gt;&lt;/a&gt; &lt;/div&gt; &lt;div class="field field--name-field-caption field--type-string field--label-hidden field__items"&gt; &lt;div class="rhd-c-caption field__item"&gt; Figure 5: Changes to the local application during remote development send updates continuously to the services in the cloud. &lt;/div&gt; &lt;/div&gt; &lt;/article&gt;&lt;/div&gt; &lt;figcaption class="rhd-c-caption"&gt;Figure 5: Changes to the local application in remote development mode continuously send updates to the remote instance.&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;You can then interact with the system through its user interface. Quarkus incrementally synchronizes the changes with the remote instance on the Kubernetes cluster as you make changes to the &lt;code&gt;rest-fights&lt;/code&gt; microservice. If you want, you could even use breakpoints within your IDE on your local machine to assist with debugging.&lt;/p&gt; &lt;h3&gt;Skupper&lt;/h3&gt; &lt;p&gt;&lt;a href="https://skupper.io"&gt;Skupper&lt;/a&gt; is a layer 7 service interconnect that enables secure communication across Kubernetes clusters without VPNs or special firewall rules. Using Skupper, an application can span multiple cloud providers, data centers, and regions. Figure 6 shows a high-level view of Skupper.&lt;/p&gt; &lt;figure class="align-center rhd-u-has-filter-caption" role="group"&gt;&lt;div class="rhd-c-figure"&gt; &lt;article class="media media--type-image media--view-mode-article-content"&gt;&lt;div class="field field--name-image field--type-image field--label-hidden field__items"&gt; &lt;a href="https://developers.redhat.com/sites/default/files/overview.png" data-featherlight="image"&gt;&lt;img loading="lazy" src="https://developers.redhat.com/sites/default/files/styles/article_floated/public/overview.png?itok=RXxczIfj" width="600" height="222" alt="Skupper connects services on different sites using routers at network layer 7." typeof="Image" /&gt;&lt;/a&gt; &lt;/div&gt; &lt;div class="field field--name-field-caption field--type-string field--label-hidden field__items"&gt; &lt;div class="rhd-c-caption field__item"&gt; Figure 6: Skupper connects services on different sites using routers at network layer 7. &lt;/div&gt; &lt;/div&gt; &lt;/article&gt;&lt;/div&gt; &lt;figcaption class="rhd-c-caption"&gt;Figure 6: Logically, Skupper connects services on different sites together to exist as a single site.&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;With Skupper, you can create a distributed application comprised of microservices running in different namespaces within different Kubernetes clusters. Services exposed to Skupper are subsequently exposed to each namespace as if they existed in the namespace. Skupper creates proxy endpoints to make a service available within each of the namespaces where it is installed. Figure 7 shows a logical view of this architecture.&lt;/p&gt; &lt;div class="rhd-c-figure"&gt; &lt;article class="align-center media media--type-image media--view-mode-article-content"&gt;&lt;div class="field field--name-image field--type-image field--label-hidden field__items"&gt; &lt;a href="https://developers.redhat.com/sites/default/files/view_0.png" data-featherlight="image"&gt;&lt;img loading="lazy" src="https://developers.redhat.com/sites/default/files/styles/article_floated/public/view_0.png?itok=w67RqnD9" width="600" height="248" alt="Logically, Skupper can span multiple Kubernetes clusters and make remote services appear as local ones." typeof="Image" /&gt;&lt;/a&gt; &lt;/div&gt; &lt;div class="field field--name-field-caption field--type-string field--label-hidden field__items"&gt; &lt;div class="rhd-c-caption field__item"&gt; Figure 7: Logically, Skupper can span multiple Kubernetes clusters and make remote services appear as local ones. &lt;/div&gt; &lt;/div&gt; &lt;/article&gt;&lt;/div&gt; &lt;p&gt;Why do we mention Skupper in an article about Kubernetes native inner loop development? Because in addition to bridging applications across Kubernetes clusters, a Skupper proxy can run on any machine, enabling bidirectional communication between the machine and the other Kubernetes clusters.&lt;/p&gt; &lt;p&gt;Logically, this is like a local machine inserted into the middle of a set of Kubernetes clusters. Services exposed to Skupper on the clusters can discover services exposed to the Skupper proxy on the local machine and vice versa.&lt;/p&gt; &lt;p&gt;Skupper can make our Quarkus Superheroes example even more interesting, taking it further from the remote development scenario we described earlier.&lt;/p&gt; &lt;p&gt;With Skupper, rather than continuously synchronizing changes to the &lt;code&gt;rest-fights&lt;/code&gt; service from a local instance to a remote instance, you could completely replace the remote &lt;code&gt;rest-fights&lt;/code&gt; instance with a local instance running Quarkus dev mode and continuous testing.&lt;/p&gt; &lt;p&gt;Skupper would then redirect traffic on the Kubernetes cluster &lt;em&gt;into&lt;/em&gt; the &lt;code&gt;rest-fights&lt;/code&gt; service running on your local machine. Any outgoing requests made by the &lt;code&gt;rest-fights&lt;/code&gt; service, such as connections to the MongoDB, Apicurio registry, and Apache Kafka instances, and even the &lt;code&gt;rest-heroes&lt;/code&gt; and &lt;code&gt;rest-villains&lt;/code&gt; services, would then be redirected back to the Kubernetes cluster. Figure 8 shows a logical view of what this architecture might look like.&lt;/p&gt; &lt;div class="rhd-c-figure"&gt; &lt;article class="align-center media media--type-image media--view-mode-article-content"&gt;&lt;div class="field field--name-image field--type-image field--label-hidden field__items"&gt; &lt;a href="https://developers.redhat.com/sites/default/files/fig8_0.png" data-featherlight="image"&gt;&lt;img loading="lazy" src="https://developers.redhat.com/sites/default/files/styles/article_floated/public/fig8_0.png?itok=W2SZheJC" width="512" height="592" alt="Diagram showing that, logically, Skupper can make it look like a local developer machine is inside a Kubernetes cluster." typeof="Image" /&gt;&lt;/a&gt; &lt;/div&gt; &lt;div class="field field--name-field-caption field--type-string field--label-hidden field__items"&gt; &lt;div class="rhd-c-caption field__item"&gt; Figure 8: Logically, Skupper can make it look like a local developer machine is inside a Kubernetes cluster. &lt;/div&gt; &lt;/div&gt; &lt;/article&gt;&lt;/div&gt; &lt;p&gt;You could even use Quarkus dev services to allow the &lt;code&gt;rest-fights&lt;/code&gt; microservice to provide its own local MongoDB instance rather than using the instance on the cluster, yet continue to let traffic to Kafka flow onto the cluster. This setup would enable other Kafka consumers listening on the same topic to continue functioning.&lt;/p&gt; &lt;p&gt;In this scenario, Quarkus continuously runs the tests of the &lt;code&gt;rest-fights&lt;/code&gt; microservice while a developer makes live code changes, all while traffic is continually flowing through the whole system on the Kubernetes cluster. The services could even be spread out to other Kubernetes clusters on different cloud providers in other regions of the world while traffic continues to flow through a developer's local machine.&lt;/p&gt; &lt;h2&gt;A better developer experience, whether local or distributed&lt;/h2&gt; &lt;p&gt;Parts &lt;a href="https://eng.lyft.com/scaling-productivity-on-microservices-at-lyft-part-2-optimizing-for-fast-local-development-9f27a98b47ee"&gt;two&lt;/a&gt; and &lt;a href="https://eng.lyft.com/scaling-productivity-on-microservices-at-lyft-part-3-extending-our-envoy-mesh-with-staging-fdaafafca82f"&gt;three&lt;/a&gt; of the previously mentioned &lt;a href="https://eng.lyft.com/scaling-productivity-on-microservices-at-lyft-part-1-a2f5d9a77813"&gt;article series at Lyft&lt;/a&gt; show Lyft's approach to solving this problem, albeit using different technologies. As more and more services came to life, Lyft saw that what they were doing wasn't scaling and that they therefore needed a kind of "remocal" environment.&lt;/p&gt; &lt;p&gt;Quarkus was designed with many of these Developer Joy characteristics in mind. Quarkus helps developers iterate faster and contains built-in capabilities that alleviate many of these challenges and shorten the development lifecycles. Developers can focus on writing code.&lt;/p&gt; The post &lt;a href="https://developers.redhat.com/articles/2022/12/12/kubernetes-native-inner-loop-development-quarkus" title="Kubernetes-native inner loop development with Quarkus"&gt;Kubernetes-native inner loop development with Quarkus&lt;/a&gt; appeared first on &lt;a href="https://developers.redhat.com/blog" title="Red Hat Developer"&gt;Red Hat Developer&lt;/a&gt;. &lt;br /&gt;&lt;br /&gt;</summary><dc:creator>Eric Deandrea</dc:creator><dc:date>2022-12-12T07:00:00Z</dc:date></entry><entry><title type="html">Kogito 1.31.0 released!</title><link rel="alternate" href="https://blog.kie.org/2022/12/kogito-1-31-0-released.html" /><author><name>Cristiano Nicolai</name></author><id>https://blog.kie.org/2022/12/kogito-1-31-0-released.html</id><updated>2022-12-12T01:49:18Z</updated><content type="html">We are glad to announce that the Kogito 1.31.0 release is now available! This goes hand in hand with , release. From a feature point of view, we have included a series of new features and bug fixes, including: * Quarkus 2.14 integration * First alpha version of the * New OpenAPI Callback example within Serverless Workflows * Sysout custom type now supports hardcoded strings (before it was only supporting expressions)  For more details head to the complete . All artifacts are available now: * Kogito runtime artifacts are available on Maven Central. * Kogito examples can be found . * Kogito images are available on . * Kogito operator is available in the in OpenShift and Kubernetes. * Kogito tooling 0.25.0 artifacts are available at the . A detailed changelog for 1.31.0 can be found in . New to Kogito? Check out our website . Click the "Get Started" button. The post appeared first on .</content><dc:creator>Cristiano Nicolai</dc:creator></entry><entry><title type="html">Revised edition of WildFly books now available!</title><link rel="alternate" href="http://www.mastertheboss.com/articles/news/revised-edition-of-wildfly-books-now-available/" /><author><name>F.Marchioni</name></author><id>http://www.mastertheboss.com/articles/news/revised-edition-of-wildfly-books-now-available/</id><updated>2022-12-10T11:59:16Z</updated><content type="html">Fresh take on WildFly Administration Guide and Practical Enterprise Application development. Both books are now Jakarta EE 10 ready! WildFly 27 has just been released featuring lots of new features and Compatibility Certification for Jakarta EE 10. I’m thrilled to announce that the books “WildFly Administration Guide” and “Practical Enterprise Application development” are now on ... The post appeared first on .</content><dc:creator>F.Marchioni</dc:creator></entry><entry><title type="html">New WildFly S2I and Runtime Multi-arch Images</title><link rel="alternate" href="https://wildfly.org//news/2022/12/10/wildfly-s2i-images-rename-multi-archs/" /><author><name>Jean-François Denise</name></author><id>https://wildfly.org//news/2022/12/10/wildfly-s2i-images-rename-multi-archs/</id><updated>2022-12-10T00:00:00Z</updated><content type="html">This article provides details on the new S2I and runtime multi-arch images. NEW WILDFLY S2I AND RUNTIME MULTI-ARCH IMAGES These new multi-arch images (linux/arm64 in addition to linux/amd64) have a different naming scheme than the current WildFly images to better handle multiple JDK versions and align with the tag scheme used for the WildFly centos7 docker images (as explained in blog post). Note The previous WildFly images are now deprecated and are no longer updated. The new multi-arch image names are: * Runtime image: quay.io/wildfly/wildfly-runtime:&lt;tag&gt; * S2I builder image: quay.io/wildfly/wildfly-s2i:&lt;tag&gt; This change is described in this . In short, the WildFly image names used to contain the JDK version (e.g: wildfly/wildfly-s2i-jdk11) leading to some lack of flexibility: * An increasing number of new images for each new JDK version. * No ability to identify a pair of images supporting the latest LTS (Long Term Support) JDK. The JDK version has been removed from the image name and moved to the image tag. In addition we have introduced a latest tag that identifies the images supporting the latest LTS JDK. You can identify the exact images version supporting a given JDK version: * quay.io/wildfly/wildfly-runtime:1.0.0-jdk11 used to be quay.io/wildfly/wildfly-runtime-jdk11:1.0.0 * quay.io/wildfly/wildfly-runtime:1.0.0-jdk17 used to be quay.io/wildfly/wildfly-runtime-jdk17:1.0.0 * quay.io/wildfly/wildfly-s2i:1.0.0-jdk11 used to be quay.io/wildfly/wildfly-s2i-jdk11:1.0.0 * quay.io/wildfly/wildfly-s2i:1.0.0-jdk17 used to be quay.io/wildfly/wildfly-s2i-jdk17:1.0.0 You can identify the latest images supporting a given JDK version: * quay.io/wildfly/wildfly-runtime:latest-jdk11 used to be quay.io/wildfly/wildfly-runtime-jdk11:latest * quay.io/wildfly/wildfly-runtime:latest-jdk17 used to be quay.io/wildfly/wildfly-runtime-jdk17:latest * quay.io/wildfly/wildfly-s2i:latest-jdk11 used to be quay.io/wildfly/wildfly-s2i-jdk11:latest * quay.io/wildfly/wildfly-s2i:latest-jdk17 used to be quay.io/wildfly/wildfly-s2i-jdk17:latest You can now identify the latest image supporting the latest LTS JDK version (JDK 17 at the time of this writing): * quay.io/wildfly/wildfly-runtime:latest * quay.io/wildfly/wildfly-s2i:latest Note Relying on this image tag implies that the JDK version will get automatically updated when a new LTS JDK is released and supported by the WildFly images. DEPRECATED SNAPSHOT MULTI-ARCH IMAGES Up to now, we were releasing multi-arch images as preview ones in the quay.io/wildfly-snapshots organization: * quay.io/wildfly-snapshots/wildfly-runtime-jdk11-multi-arch:latest * quay.io/wildfly-snapshots/wildfly-runtime-jdk17-multi-arch:latest * quay.io/wildfly-snapshots/wildfly-s2i-jdk11-multi-arch:latest * quay.io/wildfly-snapshots/wildfly-s2i-jdk17-multi-arch:latest These images are now deprecated and no longer updated. DEPRECATED WILDFLY IMAGES The following single-arch images are now deprecated and are no longer updated: * quay.io/wildfly/wildfly-runtime-jdk11:&lt;tag&gt; * quay.io/wildfly/wildfly-runtime-jdk17:&lt;tag&gt; * quay.io/wildfly/wildfly-s2i-jdk11:&lt;tag&gt; * quay.io/wildfly/wildfly-s2i-jdk17:&lt;tag&gt; NEW OPENSHIFT IMAGE STREAMS The previous image streams (, , , ) have been deprecated. The new image streams are: * WildFly s2i builder: * WildFly runtime: IMPACT ON HELM CHARTS FOR WILDFLY version 2.3.1 is required to use these new images. Helm Chart for WildFly now uses the quay.io/wildfly/wildfly-s2i:latest and quay.io/wildfly/wildfly-runtime:latest (latest LTS JDK) by default, used to be JDK11. If you have already installed the Helm Charts for WildFly, make sure to update your repository to the latest version. This is done by calling: helm repo update USING THE IMAGES The image naming change is transparent when using Helm Charts for WildFly. Usage of these images is covered by WildFly S2I , , wildfly-s2i image and wildfly-runtime image . SUMMARY With the introduction of these new multi-arch images, we are putting in place a long term tagging scheme to better support future JDK versions. You feedback as always is very welcome. Feel free to log these as new . Thank-you! JF Denise</content><dc:creator>Jean-François Denise</dc:creator></entry><entry><title>Top Ansible and automation resources of 2022</title><link rel="alternate" href="https://developers.redhat.com/articles/2022/12/09/best-2022-ansible-and-automation" /><author><name>Heiker Medina</name></author><id>2771afe8-efb6-427f-9d01-e358e4970bfe</id><updated>2022-12-09T17:48:43Z</updated><published>2022-12-09T17:48:43Z</published><summary type="html">&lt;p&gt;Developers are increasingly turning to &lt;a href="https://developers.redhat.com/topics/automation"&gt;automated development and deployment processes&lt;/a&gt; to meet the challenge of building cloud-native applications. In the era of cloud computing, your apps must react to &lt;a href="https://developers.redhat.com/topics/event-driven/"&gt;event-driven systems&lt;/a&gt; in scalable and flexible ways. Learn more about how Red Hat Developer readers used Ansible and Helm to make this possible in 2022.&lt;/p&gt; &lt;p&gt;Don't miss the other articles in our Best of 2022 series:&lt;/p&gt; &lt;ul&gt;&lt;li&gt;&lt;a href="https://developers.redhat.com/articles/2022/12/01/top-linux-resources-2022"&gt;Top Linux resources of 2022&lt;/a&gt;&lt;/li&gt; &lt;li&gt;&lt;a href="https://developers.redhat.com/articles/2022/12/06/top-kubernetes-and-openshift-resources-2022"&gt;Top Kubernetes and OpenShift resources of 2022&lt;/a&gt;&lt;/li&gt; &lt;/ul&gt;&lt;h2&gt;API management&lt;/h2&gt; &lt;p&gt;Quarkus has made great progress in the past year, and its &lt;a href="https://developers.redhat.com/articles/2022/02/03/build-rest-api-ground-quarkus-20"&gt;tooling and overall usability have improved significantly&lt;/a&gt;. It is still fast and lightweight, and if you are looking for a modern Java framework for your next project, then Quarkus should be at the top of your list. If you're building an API, &lt;a href="https://developers.redhat.com/articles/2022/10/06/how-make-your-apis-more-discoverable"&gt;follow this guide by Vamsi Ravula and Hugo Guerrero&lt;/a&gt;. It's important to think about how people will find the API before you build it so that you don't have to come up with something on the fly.&lt;/p&gt; &lt;p&gt;To make sure your API is secure, use these &lt;a href="https://developers.redhat.com/articles/2022/10/20/10-essentials-mitigating-api-security-risks#how_red_hat_secures_apis"&gt;ten solutions and tools to help manage security&lt;/a&gt; throughout each step of the API life cycle.&lt;/p&gt; &lt;p&gt;To develop a successful API program, it is important to provide your developers with a developer portal that they can use to access your APIs. Vamsi Ravula shows you &lt;a href="https://developers.redhat.com/articles/2022/05/05/build-customized-developer-portal-manage-apis"&gt;how Red Hat 3scale API Management can be deployed on Red Hat OpenShift&lt;/a&gt; to provide a customizable developer portal. The procedure in this article shows the power of &lt;a href="https://developers.redhat.com/products/openshift/overview"&gt;Red Hat OpenShift&lt;/a&gt; as an application development platform, and how developers can get access to all of these components from the OpenShift console.&lt;/p&gt; &lt;h2&gt;Helm&lt;/h2&gt; &lt;p&gt;Jose Carvajal Hilario and Charles Moulliard demonstrated &lt;a href="https://developers.redhat.com/articles/2022/10/12/generate-helm-charts-using-dekorate"&gt;three ways that Dekorate simplifies Helm chart generation&lt;/a&gt;: it lets you easily generate Helm charts, it helps you map properties to be set when installing or updating your charts, and it allows you to use profiles.&lt;/p&gt; &lt;p&gt;Rohan Kumar shows you &lt;a href="https://developers.redhat.com/articles/2022/08/01/how-configure-helm-charts-using-jkube-part-2"&gt;how to set up Helm charts using Maven and Gradle plugins&lt;/a&gt;, with configuration options from Eclipse JKube. The article covers XML, Java properties, and resource fragments, finishing up by demonstrating how to configure a Helm registry to store your configuration.&lt;/p&gt; &lt;h2&gt;Ansible&lt;/h2&gt; &lt;p&gt;If you're interested in Ansible for middleware series, you'll want to read Romain Pelisse's article on &lt;a href="https://developers.redhat.com/articles/2022/04/20/deploy-keycloak-single-sign-ansible"&gt;using Ansible to simplify the installation of Keycloak&lt;/a&gt;, an open source identity provider that enables single sign-on functionality for Web applications.&lt;/p&gt; &lt;p&gt;Red Hat Ansible Automation Platform also enables developers to &lt;a href="https://developers.redhat.com/articles/2022/09/07/5-examples-security-automation-ansible"&gt;automate the deployment and configuration of security tools&lt;/a&gt;, including firewalls, IDS/IPSes, SIEMs, PAMs, and EPPs. Jamie Beck and Himanshu Yadav explore five common use cases for automating these technologies.&lt;/p&gt; &lt;p&gt;In Harsha Cherukuri's article, he uses &lt;a href="https://developers.redhat.com/articles/2022/08/17/how-ansible-simplifies-jboss-eap-deployment-azure"&gt;Ansible to create Azure resources&lt;/a&gt;, deploys JBoss EAP using WildFly, and then deploys WildFly on an Azure VM.&lt;/p&gt; &lt;p&gt;Finally, revisit 2022's big Ansible announcement: &lt;a href="https://developers.redhat.com/blog/2022/11/29/whats-new-ansible-automation-platform-23"&gt;Ansible Automation Platform 2.3&lt;/a&gt; makes it easier than ever to automate system configuration, application deployment, and network settings across your entire enterprise via code.&lt;/p&gt; &lt;h2&gt;CI/CD&lt;/h2&gt; &lt;p&gt;In this &lt;a href="https://developers.redhat.com/articles/2022/01/13/developers-guide-cicd-and-gitops-jenkins-pipelines"&gt;tutorial article&lt;/a&gt;, Bob Reselman starts with a brief review of what Jenkins is and what it can do. Then, he explains how to use a Jenkinsfile to create deployments that combine CI/CD and GitOps.&lt;/p&gt; &lt;p&gt;Dotnet build-image is a tool that helps you containerize your .NET applications. You can use it to generate Dockerfiles and containerized images, and you'll discover with Tom Deseyn how to work with this tool in a GitHub workflow to &lt;a href="https://developers.redhat.com/articles/2022/08/01/containerize-net-applications-without-writing-dockerfiles"&gt;create an image from a .NET application and push it to a repository&lt;/a&gt;&lt;/p&gt; &lt;p&gt;Red Hat Developer has put together a collection of our &lt;a href="https://developers.redhat.com/articles/2022/10/20/ultimate-cicd-resource-guide#recent_articles_to_explore_about_ci_cd"&gt;highest-performing articles on CI/CD&lt;/a&gt;. This article will introduce you to all things related to this topic.&lt;/p&gt; &lt;p&gt;In Christian Hernandez's article &lt;a href="https://developers.redhat.com/articles/2022/09/07/how-set-your-gitops-directory-structure"&gt;How to set up your GitOps directory structure&lt;/a&gt;, he discusses how to create repositories and directories in GitOps. Although there is no one answer, these basic best practices can help you see where to start.&lt;/p&gt; &lt;h2&gt;Resources&lt;/h2&gt; &lt;p&gt;Automation helps scale infrastructure, strengthen security, and improve customer experience. In the short e-book &lt;em&gt;An IT executive's guide to automation,&lt;/em&gt; you will discover the &lt;a href="https://developers.redhat.com/e-books/it-executives-guide-automation"&gt;benefits of a long-term transformative automation strategy&lt;/a&gt;. You'll also find out how to automate your infrastructure with Red Hat. Another resource to review is our &lt;a href="https://developers.redhat.com/cheat-sheets/git-cheat-sheet"&gt;basic Git commands cheat sheet&lt;/a&gt; The commands you'll learn more about help you work with files along with repositories and their branches, resolve merge conflicts, and more. You'll also learn how to move content between the remote repository and your local workspace, rebase or merge files between branches, and resolve merge conflicts when they occur.&lt;/p&gt; &lt;h2&gt;Learning paths&lt;/h2&gt; &lt;p&gt;You can simplify your IT tasks by creating a centralized and automated process with Ansible. Review &lt;a href="https://developers.redhat.com/learn/ansible"&gt;Red Hat Developer's Ansible learning path&lt;/a&gt; today!&lt;/p&gt; The post &lt;a href="https://developers.redhat.com/articles/2022/12/09/best-2022-ansible-and-automation" title="Top Ansible and automation resources of 2022"&gt;Top Ansible and automation resources of 2022&lt;/a&gt; appeared first on &lt;a href="https://developers.redhat.com/blog" title="Red Hat Developer"&gt;Red Hat Developer&lt;/a&gt;. &lt;br /&gt;&lt;br /&gt;</summary><dc:creator>Heiker Medina</dc:creator><dc:date>2022-12-09T17:48:43Z</dc:date></entry><entry><title type="html">Using JBeret With Quarkus</title><link rel="alternate" href="https://jberet.github.io/jberet-quarkus/" /><author><name>阿男</name></author><id>https://jberet.github.io/jberet-quarkus/</id><updated>2022-12-09T00:00:00Z</updated><dc:creator>阿男</dc:creator></entry><entry><title type="html">Integrate Red Hat Process Automation Manager with Springboot</title><link rel="alternate" href="https://blog.kie.org/2022/12/integrate-red-hat-process-automation-manager-with-springboot.html" /><author><name>Archana Krishnan</name></author><id>https://blog.kie.org/2022/12/integrate-red-hat-process-automation-manager-with-springboot.html</id><updated>2022-12-08T23:16:25Z</updated><content type="html">We worked on a request to migrate RHPAM/EAP applications to RHPAM/Springboot. The following steps were adopted to help the client move into RHPAM/Springboot containers. ENVIRONMENT: * Red Hat Process Automation Manager (7.12.1) connected to PostgreSQL * Red Hat AMQ 7.10 * Red Hat Openshift Container Platform 4.10 DATABASE CONFIGURATION: There are differences in the sequence configured for RHPAM/EAP application and RHPAM/Springboot applications. Please run the below script to update sequence: alter sequence BAM_TASK_ID_SEQ increment by 50; alter sequence CASE_ID_INFO_ID_SEQ increment by 50; alter sequence CONTEXT_MAPPING_INFO_ID_SEQ increment by 50; alter sequence CORRELATION_KEY_ID_SEQ increment by 50; alter sequence CORRELATION_PROP_ID_SEQ increment by 50; alter sequence ERROR_INFO_ID_SEQ increment by 50; alter sequence PROCESS_INSTANCE_INFO_ID_SEQ increment by 50; alter sequence REQUEST_INFO_ID_SEQ increment by 50; alter sequence SESSIONINFO_ID_SEQ increment by 50; alter sequence TASK_DEF_ID_SEQ increment by 50; alter sequence TASK_EVENT_ID_SEQ increment by 50; alter sequence WORKITEMINFO_ID_SEQ increment by 50; Update application.properties with the following properties to connect to PostgreSQL: spring.datasource.username=jbpm spring.datasource.password=jbpm spring.datasource.url=jdbc:postgresql://localhost:5432/jbpm spring.datasource.driver-class-name=org.postgresql.Driver spring.jpa.properties.hibernate.dialect=org.hibernate.dialect.PostgreSQLDialect spring.jpa.hibernate.ddl-auto=validate spring.jpa.hibernate.naming.physical-strategy=org.hibernate.boot.model.naming.PhysicalNamingStrategyStandardImpl PersistenceException is expected if the sequence is not updated and RHPAM/Springboot application tries to connect to the database: org.springframework.beans.factory.BeanCreationException: Error creating bean with name 'entityManagerFactory' defined in class path resource [org/jbpm/springboot/autoconfigure/JBPMAutoConfiguration.class]: Invocation of init method failed; nested exception is javax.persistence.PersistenceException: [PersistenceUnit: org.jbpm.domain] Unable to build Hibernate SessionFactory; nested exception is org.hibernate.MappingException: Could not instantiate id generator [entity-name=org.jbpm.services.task.impl.model.TaskDefImpl] Caused by: org.hibernate.MappingException: The increment size of the [TASK_DEF_ID_SEQ] sequence is set to [50] in the entity mapping while the associated database sequence increment size is [1]. AMQ CONFIGURATION: Update the application.properties with the following parameters to connect to AMQ: amqphub.amqp10jms.remoteUrl=amqp://localhost:5672 amqphub.amqp10jms.username=admin amqphub.amqp10jms.password=admin jms.queue.destination=request-queue KIE SERVER CONFIGURATION: Update application.properties with the following properties: server.address=0.0.0.0 server.port=8090 cxf.path=/rest #kie server config kieserver.serverId=sp-sb-kie-server kieserver.serverName=sp-sb-kie-server kieserver.location=http://localhost:8090/rest/server kieserver.classPathContainer=true #kie server capabilities kieserver.drools.enabled=true kieserver.dmn.enabled=true kieserver.jbpm.enabled=true kieserver.jbpmui.enabled=true kieserver.casemgmt.enabled=true #kieserver.prometheus.enabled=true kieserver.swagger.enabled=true kieserver.deployments[&lt;n&gt;].containerId=&lt;container&gt; kieserver.deployments[&lt;n&gt;].alias=&lt;alias&gt; kieserver.deployments[&lt;n&gt;].artifactId=&lt;artifact&gt; kieserver.deployments[&lt;n&gt;].groupId=&lt;group&gt; kieserver.deployments[&lt;n&gt;].version=&lt;version&gt; #jbpm configuration jbpm.executor.enabled=true jbpm.executor.retries=5 jbpm.executor.interval=3 jbpm.executor.threadPoolSize=10 jbpm.executor.timeUnit=SECONDS #transaction manager configuration spring.jta.narayana.transaction-manager-id=1 #banner spring.banner.location=classpath:banner.txt narayana.transaction-manager-id=1 narayana.default-timeout=120 narayana.dbcp.enabled=true #logging logging.level.org.kie: INFO logging.level.org.jbpm: ERROR QUARTZ TIMER CONFIGURATION: DDL script to include DB configuration for quartz timer: CREATE TABLE qrtz_job_details ( SCHED_NAME VARCHAR(120) NOT NULL, JOB_NAME VARCHAR(200) NOT NULL, JOB_GROUP VARCHAR(200) NOT NULL, DESCRIPTION VARCHAR(250) NULL, JOB_CLASS_NAME VARCHAR(250) NOT NULL, IS_DURABLE BOOL NOT NULL, IS_NONCONCURRENT BOOL NOT NULL, IS_UPDATE_DATA BOOL NOT NULL, REQUESTS_RECOVERY BOOL NOT NULL, JOB_DATA BYTEA NULL, PRIMARY KEY (SCHED_NAME,JOB_NAME,JOB_GROUP) ); CREATE TABLE qrtz_triggers ( SCHED_NAME VARCHAR(120) NOT NULL, TRIGGER_NAME VARCHAR(200) NOT NULL, TRIGGER_GROUP VARCHAR(200) NOT NULL, JOB_NAME VARCHAR(200) NOT NULL, JOB_GROUP VARCHAR(200) NOT NULL, DESCRIPTION VARCHAR(250) NULL, NEXT_FIRE_TIME BIGINT NULL, PREV_FIRE_TIME BIGINT NULL, PRIORITY INTEGER NULL, TRIGGER_STATE VARCHAR(16) NOT NULL, TRIGGER_TYPE VARCHAR(8) NOT NULL, START_TIME BIGINT NOT NULL, END_TIME BIGINT NULL, CALENDAR_NAME VARCHAR(200) NULL, MISFIRE_INSTR SMALLINT NULL, JOB_DATA BYTEA NULL, PRIMARY KEY (SCHED_NAME,TRIGGER_NAME,TRIGGER_GROUP), FOREIGN KEY (SCHED_NAME,JOB_NAME,JOB_GROUP) REFERENCES QRTZ_JOB_DETAILS(SCHED_NAME,JOB_NAME,JOB_GROUP) ); CREATE TABLE qrtz_simple_triggers ( SCHED_NAME VARCHAR(120) NOT NULL, TRIGGER_NAME VARCHAR(200) NOT NULL, TRIGGER_GROUP VARCHAR(200) NOT NULL, REPEAT_COUNT BIGINT NOT NULL, REPEAT_INTERVAL BIGINT NOT NULL, TIMES_TRIGGERED BIGINT NOT NULL, PRIMARY KEY (SCHED_NAME,TRIGGER_NAME,TRIGGER_GROUP), FOREIGN KEY (SCHED_NAME,TRIGGER_NAME,TRIGGER_GROUP) REFERENCES QRTZ_TRIGGERS(SCHED_NAME,TRIGGER_NAME,TRIGGER_GROUP) ); CREATE TABLE qrtz_cron_triggers ( SCHED_NAME VARCHAR(120) NOT NULL, TRIGGER_NAME VARCHAR(200) NOT NULL, TRIGGER_GROUP VARCHAR(200) NOT NULL, CRON_EXPRESSION VARCHAR(120) NOT NULL, TIME_ZONE_ID VARCHAR(80), PRIMARY KEY (SCHED_NAME,TRIGGER_NAME,TRIGGER_GROUP), FOREIGN KEY (SCHED_NAME,TRIGGER_NAME,TRIGGER_GROUP) REFERENCES QRTZ_TRIGGERS(SCHED_NAME,TRIGGER_NAME,TRIGGER_GROUP) ); CREATE TABLE qrtz_simprop_triggers ( SCHED_NAME VARCHAR(120) NOT NULL, TRIGGER_NAME VARCHAR(200) NOT NULL, TRIGGER_GROUP VARCHAR(200) NOT NULL, STR_PROP_1 VARCHAR(512) NULL, STR_PROP_2 VARCHAR(512) NULL, STR_PROP_3 VARCHAR(512) NULL, INT_PROP_1 INT NULL, INT_PROP_2 INT NULL, LONG_PROP_1 BIGINT NULL, LONG_PROP_2 BIGINT NULL, DEC_PROP_1 NUMERIC(13,4) NULL, DEC_PROP_2 NUMERIC(13,4) NULL, BOOL_PROP_1 BOOL NULL, BOOL_PROP_2 BOOL NULL, PRIMARY KEY (SCHED_NAME,TRIGGER_NAME,TRIGGER_GROUP), FOREIGN KEY (SCHED_NAME,TRIGGER_NAME,TRIGGER_GROUP) REFERENCES QRTZ_TRIGGERS(SCHED_NAME,TRIGGER_NAME,TRIGGER_GROUP) ); CREATE TABLE qrtz_blob_triggers ( SCHED_NAME VARCHAR(120) NOT NULL, TRIGGER_NAME VARCHAR(200) NOT NULL, TRIGGER_GROUP VARCHAR(200) NOT NULL, BLOB_DATA BYTEA NULL, PRIMARY KEY (SCHED_NAME,TRIGGER_NAME,TRIGGER_GROUP), FOREIGN KEY (SCHED_NAME,TRIGGER_NAME,TRIGGER_GROUP) REFERENCES QRTZ_TRIGGERS(SCHED_NAME,TRIGGER_NAME,TRIGGER_GROUP) ); CREATE TABLE qrtz_calendars ( SCHED_NAME VARCHAR(120) NOT NULL, CALENDAR_NAME VARCHAR(200) NOT NULL, CALENDAR BYTEA NOT NULL, PRIMARY KEY (SCHED_NAME,CALENDAR_NAME) ); CREATE TABLE qrtz_paused_trigger_grps ( SCHED_NAME VARCHAR(120) NOT NULL, TRIGGER_GROUP VARCHAR(200) NOT NULL, PRIMARY KEY (SCHED_NAME,TRIGGER_GROUP) ); CREATE TABLE qrtz_fired_triggers ( SCHED_NAME VARCHAR(120) NOT NULL, ENTRY_ID VARCHAR(95) NOT NULL, TRIGGER_NAME VARCHAR(200) NOT NULL, TRIGGER_GROUP VARCHAR(200) NOT NULL, INSTANCE_NAME VARCHAR(200) NOT NULL, FIRED_TIME BIGINT NOT NULL, SCHED_TIME BIGINT NOT NULL, PRIORITY INTEGER NOT NULL, STATE VARCHAR(16) NOT NULL, JOB_NAME VARCHAR(200) NULL, JOB_GROUP VARCHAR(200) NULL, IS_NONCONCURRENT BOOL NULL, REQUESTS_RECOVERY BOOL NULL, PRIMARY KEY (SCHED_NAME,ENTRY_ID) ); CREATE TABLE qrtz_scheduler_state ( SCHED_NAME VARCHAR(120) NOT NULL, INSTANCE_NAME VARCHAR(200) NOT NULL, LAST_CHECKIN_TIME BIGINT NOT NULL, CHECKIN_INTERVAL BIGINT NOT NULL, PRIMARY KEY (SCHED_NAME,INSTANCE_NAME) ); CREATE TABLE qrtz_locks ( SCHED_NAME VARCHAR(120) NOT NULL, LOCK_NAME VARCHAR(40) NOT NULL, PRIMARY KEY (SCHED_NAME,LOCK_NAME) ); create index idx_qrtz_j_req_recovery on qrtz_job_details(SCHED_NAME,REQUESTS_RECOVERY); create index idx_qrtz_j_grp on qrtz_job_details(SCHED_NAME,JOB_GROUP); create index idx_qrtz_t_j on qrtz_triggers(SCHED_NAME,JOB_NAME,JOB_GROUP); create index idx_qrtz_t_jg on qrtz_triggers(SCHED_NAME,JOB_GROUP); create index idx_qrtz_t_c on qrtz_triggers(SCHED_NAME,CALENDAR_NAME); create index idx_qrtz_t_g on qrtz_triggers(SCHED_NAME,TRIGGER_GROUP); create index idx_qrtz_t_state on qrtz_triggers(SCHED_NAME,TRIGGER_STATE); create index idx_qrtz_t_n_state on qrtz_triggers(SCHED_NAME,TRIGGER_NAME,TRIGGER_GROUP,TRIGGER_STATE); create index idx_qrtz_t_n_g_state on qrtz_triggers(SCHED_NAME,TRIGGER_GROUP,TRIGGER_STATE); create index idx_qrtz_t_next_fire_time on qrtz_triggers(SCHED_NAME,NEXT_FIRE_TIME); create index idx_qrtz_t_nft_st on qrtz_triggers(SCHED_NAME,TRIGGER_STATE,NEXT_FIRE_TIME); create index idx_qrtz_t_nft_misfire on qrtz_triggers(SCHED_NAME,MISFIRE_INSTR,NEXT_FIRE_TIME); create index idx_qrtz_t_nft_st_misfire on qrtz_triggers(SCHED_NAME,MISFIRE_INSTR,NEXT_FIRE_TIME,TRIGGER_STATE); create index idx_qrtz_t_nft_st_misfire_grp on qrtz_triggers(SCHED_NAME,MISFIRE_INSTR,NEXT_FIRE_TIME,TRIGGER_GROUP,TRIGGER_STATE); create index idx_qrtz_ft_trig_inst_name on qrtz_fired_triggers(SCHED_NAME,INSTANCE_NAME); create index idx_qrtz_ft_inst_job_req_rcvry on qrtz_fired_triggers(SCHED_NAME,INSTANCE_NAME,REQUESTS_RECOVERY); create index idx_qrtz_ft_j_g on qrtz_fired_triggers(SCHED_NAME,JOB_NAME,JOB_GROUP); create index idx_qrtz_ft_jg on qrtz_fired_triggers(SCHED_NAME,JOB_GROUP); create index idx_qrtz_ft_t_g on qrtz_fired_triggers(SCHED_NAME,TRIGGER_NAME,TRIGGER_GROUP); create index idx_qrtz_ft_tg on qrtz_fired_triggers(SCHED_NAME,TRIGGER_GROUP); Add the quartz properties file at src/main/resources/quartz.properties: #============================================================================ # Configure Main Scheduler Properties #============================================================================ org.quartz.scheduler.instanceName = SpringBootScheduler org.quartz.scheduler.instanceId = AUTO org.quartz.scheduler.skipUpdateCheck=true org.quartz.scheduler.idleWaitTime=1000 #============================================================================ # Configure ThreadPool #============================================================================ org.quartz.threadPool.class = org.quartz.simpl.SimpleThreadPool org.quartz.threadPool.threadCount = 5 org.quartz.threadPool.threadPriority = 5 #============================================================================ # Configure JobStore #============================================================================ org.quartz.jobStore.misfireThreshold = 60000 org.quartz.jobStore.class=org.quartz.impl.jdbcjobstore.JobStoreCMT org.quartz.jobStore.driverDelegateClass=org.quartz.impl.jdbcjobstore.PostgreSQLDelegate org.quartz.jobStore.useProperties=false org.quartz.jobStore.dataSource=myDS org.quartz.jobStore.nonManagedTXDataSource=notManagedDS org.quartz.jobStore.tablePrefix=QRTZ_ org.quartz.jobStore.isClustered=true org.quartz.jobStore.clusterCheckinInterval = 5000 #============================================================================ # Configure Datasources #============================================================================ org.quartz.dataSource.myDS.connectionProvider.class=org.jbpm.springboot.quartz.SpringConnectionProvider org.quartz.dataSource.myDS.dataSourceName=quartzDataSource org.quartz.dataSource.notManagedDS.connectionProvider.class=org.jbpm.springboot.quartz.SpringConnectionProvider org.quartz.dataSource.notManagedDS.dataSourceName=quartzNotManagedDataSource Update the application.properties: jbpm.quartz.enabled=true jbpm.quartz.configuration=quartz.properties STEPS TO DEPLOY THE APPLICATION TO OCP 4.10 1. Create ocp-image directory outside the business-application project with the following structure: ocp-image |--/root |--/opt |-- /spring-service 2. Copy JAR file to root/opt/spring-service. For example: cd ../business-application cp target/business-application-1.0-SNAPSHOT.jar ../ocp-image/root/opt/spring-service/ 3. Create a Dockerfile with the following content in the directory /ocp-image/ FROM registry.access.redhat.com/ubi8/openjdk-11:latest COPY root / EXPOSE 8090 WORKDIR /opt/spring-service/ RUN chown -R jboss:root /opt/spring-service/ &amp;amp;&amp; chmod 777 /opt/spring-service/ CMD ["sh","-c", "java ${JAVA_OPTIONS} -Dorg.kie.server.mode=PRODUCTION -jar /opt/spring-service/&lt;FILENAME&gt;.jar"] 4. Build and deploy application to OCP 4.10 oc new-build --binary --strategy=docker --name kie-springboot oc start-build kie-springboot --from-dir=. --follow oc new-app kie-springboot oc expose service/kie-springboot --port=8090 The post appeared first on .</content><dc:creator>Archana Krishnan</dc:creator></entry><entry><title>How to prevent broken access control</title><link rel="alternate" href="https://developers.redhat.com/articles/2022/12/08/how-prevent-broken-access-control" /><author><name>Sandipan Roy</name></author><id>c12aed8e-fe6b-442f-800b-894056fd49f4</id><updated>2022-12-08T07:00:00Z</updated><published>2022-12-08T07:00:00Z</published><summary type="html">&lt;p&gt;There are many sophisticated forms of access control nowadays. Yet breaches are still common. Why does access control fail? This article answers that question by describing some of the flaws that lead to broken access control (also known as broken authorization or privilege escalation) and demonstrates &lt;a href="https://developers.redhat.com/topics/secure-coding"&gt;secure coding&lt;/a&gt;.&lt;/p&gt; &lt;h2&gt;What is access control?&lt;/h2&gt; &lt;p&gt;Data protection is crucial, particularly in the field of information security. Personal information, financial records, and other sensitive data should not be accessible to everyone. Access control is a critical element of data security that designates who is permitted to view or change resources and information in a computing environment. Depending on users’ specified roles and associated rights, they are either granted or refused access to different resources and functions by appropriately planned and executed authorization frameworks.&lt;/p&gt; &lt;p&gt;If access control is inadequate or flawed, a hostile actor could gain access to restricted material, edit or remove content, and carry out unauthorized tasks, even potentially take over the whole site. The only thing limiting the attack's harm is the rights given to a compromised user account.&lt;/p&gt; &lt;h2&gt;3 Methods of access control&lt;/h2&gt; &lt;p&gt;There are three general methods for implementing logical access control in a software system: &lt;/p&gt; &lt;h3&gt;1. Discretionary access control (DAC)&lt;/h3&gt; &lt;p&gt;In discretionary access control, access to particular resources is controlled by the data's owner. Users have complete control over all their objects and attributes when using this sort of access control. Access to objects can be restricted based on who is attempting to get access to them. Most operating systems implement this type of access control using attributes (read, write, execute, etc.) to indicate the rights assigned to each user for the object being protected.&lt;/p&gt; &lt;p&gt;The objects of the system (files, directories, etc.) in &lt;a href="https://developers.redhat.com/topics/linux"&gt;Linux&lt;/a&gt; systems include three traditional permissions: read (r), write (w), and execute (x). The root user grants these permissions to the group and other users (users who are not owners or members of the group).&lt;/p&gt; &lt;h3&gt;2. Role-based access control (RBAC)&lt;/h3&gt; &lt;p&gt;In a complicated system with many users and functions, discretionary access restrictions do not offer enough granularity to permit a well-defined and organized segmentation. Personnel specialists in human resources, for instance, shouldn't be allowed to create network accounts.&lt;/p&gt; &lt;p&gt;In this situation, assigning rights based on roles rather than individual users or groups offers more freedom. For instance, RBAC permits access related to job titles. RBAC substantially eliminates discretion when granting access to objects.&lt;/p&gt; &lt;p&gt;The modern solution for RBAC is the Lightweight Directory Access Protocol (LDAP). The &lt;a href="https://www.redhat.com/en/technologies/cloud-computing/directory-server"&gt;Red Hat Directory Server&lt;/a&gt; provides an affordable LDAP solution. &lt;a href="https://www.openldap.org"&gt;OpenLDAP&lt;/a&gt; and &lt;a href="https://www.freeipa.org/page/Main_Page"&gt;FreeIPA&lt;/a&gt; are open source solutions.&lt;/p&gt; &lt;h3&gt;3. Managed access control (MAC)&lt;/h3&gt; &lt;p&gt;In managed access control, a central authority controls access permissions depending on several degrees of security. This access method offers additional security for access and privilege handling.&lt;/p&gt; &lt;p&gt;MAC tags every system component before being subjected to the access control policies set by the administrators. Even when a person passes other security restrictions, MAC examines the tags. The predefined MAC policies will determine whether to permit the operation.&lt;/p&gt; &lt;p&gt;Modern Linux systems (including &lt;a href="https://developers.redhat.com/products/rhel"&gt;Red Hat Enterprise Linux&lt;/a&gt; and &lt;a href="https://getfedora.org"&gt;Fedora&lt;/a&gt;) support &lt;a href="https://selinuxproject.org/page/Main_Page"&gt;Security Enhanced Linux&lt;/a&gt; (SELinux) to provide MAC.&lt;/p&gt; &lt;h2&gt;Examples of broken access control&lt;/h2&gt; &lt;p&gt;Broken access control refers to various problems that result from the improper application of checks which determine user access. Implementing authorization across dynamic systems is difficult, and policies can become inconsistent when user roles, authentication libraries, and protocols change. All web applications, databases, operating systems, and other technical infrastructures dependent on permission restrictions are vulnerable to such flaws.&lt;/p&gt; &lt;p&gt;There are two primary types of authorization attacks to think about from the user's perspective: horizontal and vertical bypassing.&lt;/p&gt; &lt;h3&gt;Horizontal bypassing of authorization control&lt;/h3&gt; &lt;p&gt;Horizontal bypassing means that an unprivileged user gains access to other users' accounts with equivalent privileges. Consider a scenario where an application requests account information from a downstream method and accepts unscreened data from the method. An insecure downstream method might obtain account information through a query string like the following:&lt;/p&gt; &lt;pre&gt; &lt;code class="http"&gt;https://developers.redhat.com/author?Id=273801 https://developers.redhat.com/author?Id=273802&lt;/code&gt;&lt;/pre&gt; &lt;p&gt;An attacker can readily change the ID argument in the HTTP request to access data from one or many users' accounts. Similarly, when an unscreened user input directly accesses objects, it is called an insecure direct object reference (IDOR).&lt;/p&gt; &lt;h3&gt;Vertical bypassing of authorization control&lt;/h3&gt; &lt;p&gt;Vertical bypassing of authorization control means that an attacker gets a higher level of privilege (i.e., root or superuser privilege) than the system intended to grant.&lt;/p&gt; &lt;p&gt;For instance, suppose an attacker navigates to the second URL in the following example, where access to the admin dashboard should need administrative permissions:&lt;/p&gt; &lt;pre&gt; &lt;code class="language-http"&gt;https://developers.redhat.com/contributor/dashboard ​​​​​​​https://developers.redhat.com/admin/dashboard&lt;/code&gt;&lt;/pre&gt; &lt;p&gt;Suppose the service does not verify that the current user's role matches the role necessary to access particular resources. In that case, a person without administrative rights can easily access any URL by simply knowing or guessing the targeted URL and visiting it.&lt;/p&gt; &lt;h2&gt;How to prevent broken access control&lt;/h2&gt; &lt;p&gt;Developers can take several fundamental precautions to guard against broken access control attacks. A strong process begins with a review of the application's access control needs and the creation of a security policy that aligns with the results. A review should include an access control matrix, a detailed statement of what kinds of users are permitted access, and a list of the permitted and prohibited uses of that access.&lt;/p&gt; &lt;p&gt;Utilize role-based access control (RBAC) to impose proper limits on each role. Be sure that the access control mechanism is appropriately applied, on the server side, on all pages and API endpoints for web applications. Simply asking for direct access to a website or resource should not allow users to gain access to any unauthorized functionality or data.&lt;/p&gt; &lt;p&gt;Here is a checklist to prevent broken access control:&lt;/p&gt; &lt;ul&gt;&lt;li&gt;Never use obfuscation as the sole method of access control.&lt;/li&gt; &lt;li&gt;Specify the degree of access permitted for each resource at the code level, denying all access by default.&lt;/li&gt; &lt;li&gt;Deny access by default if a resource isn't meant to be shared with the general public.&lt;/li&gt; &lt;li&gt;Audit and thoroughly test access control to ensure it functions as intended.&lt;/li&gt; &lt;/ul&gt;&lt;h3&gt;A secure coding example&lt;/h3&gt; &lt;p&gt;Let's look at how to ensure proper access control in a sample program. The example in this article is written in the Go programming language, which lacks native solutions for this issue. Some other frameworks provide specialized methods for implementing strong access control.&lt;/p&gt; &lt;p&gt;The following Go framework takes some action for users who have been authenticated. The code submits the user ID to a service named​​​​​​​ &lt;code&gt;authenticationMiddleware&lt;/code&gt; to guarantee that only authorized users trigger &lt;code&gt;ActionHandler&lt;/code&gt;:&lt;/p&gt; &lt;pre&gt; &lt;code class="cpp"&gt;e := echo.New() e.POST("/action/:id", ActionHandler, authenticationMiddleware)&lt;/code&gt;&lt;/pre&gt; &lt;p&gt;This access check might not be sufficient. Correct authorization must be maintained wherever the program provides access to resources to prevent a bypass. For instance, suppose the &lt;code&gt;ActionHandler&lt;/code&gt; method invoked by the program offers access to a sensitive resource:&lt;/p&gt; &lt;pre&gt; &lt;code class="cpp"&gt;func ActionHandler(c echo.Context) error { id := c.Param("Id") resource := getResourceBy("Id") resource.Action() return c.String(http.StatusOK, "OK") }&lt;/code&gt;&lt;/pre&gt; &lt;p&gt;Developers of &lt;code&gt;ActionHandler&lt;/code&gt; must make sure that access control checks are carried out before granting access:&lt;/p&gt; &lt;pre&gt; &lt;code class="cpp"&gt;func ActionHandler(c echo.Context) error { id := c.Param("id") resource := getResourceBy("id") if resource.Owner() != getOwnerFromContext(c) { return c.String(http.StatusUnauthorized, "User is not Authorized for this Action.") } resource.Action() return c.String(http.StatusOK, "OK") }&lt;/code&gt;&lt;/pre&gt; &lt;h2&gt;Preventing broken access control is crucial&lt;/h2&gt; &lt;p&gt;Be diligent in using the tools that manage and monitor the security of your assets, even if it feels like they require a lot of work. You can find information about authorization bypassing in the&lt;a href="https://cheatsheetseries.owasp.org/cheatsheets/Authorization_Cheat_Sheet.html"&gt; OWASP CheetSheet&lt;/a&gt;. Stop cyberattacks using secure coding techniques and ongoing security testing. Learn more about secure coding practice by reviewing the&lt;a href="https://github.com/OWASP/Go-SCP"&gt; OWASP secure coding practice guide&lt;/a&gt;. Go programmers can read&lt;a href="https://nostarch.com/blackhatgo"&gt; Black Hat Go&lt;/a&gt; for information about security penetration testing.&lt;/p&gt; The post &lt;a href="https://developers.redhat.com/articles/2022/12/08/how-prevent-broken-access-control" title="How to prevent broken access control"&gt;How to prevent broken access control&lt;/a&gt; appeared first on &lt;a href="https://developers.redhat.com/blog" title="Red Hat Developer"&gt;Red Hat Developer&lt;/a&gt;. &lt;br /&gt;&lt;br /&gt;</summary><dc:creator>Sandipan Roy</dc:creator><dc:date>2022-12-08T07:00:00Z</dc:date></entry><entry><title>Cryostat 2.2's new JMX credentials keyring</title><link rel="alternate" href="https://developers.redhat.com/articles/2022/12/07/cryostat-22s-new-jmx-credentials-keyring" /><author><name>Andrew Azores</name></author><id>62f88e3f-c9bc-4983-86b3-49954cdd7765</id><updated>2022-12-07T07:00:01Z</updated><published>2022-12-07T07:00:01Z</published><summary type="html">&lt;p&gt;An important security enhancement for &lt;a href="https://developers.redhat.com/topics/enterprise-java"&gt;Java&lt;/a&gt; applications is now available through &lt;a href="https://www.oracle.com/technical-resources/articles/javase/jmx.html"&gt;Java Management Extensions&lt;/a&gt; (JMX), using open source &lt;a href="https://developers.redhat.com/blog/2020/08/25/get-started-with-jdk-flight-recorder-in-openjdk-8u"&gt;JDK Flight Recorder&lt;/a&gt; (JFR) management with &lt;a href="https://cryostat.io"&gt;Cryostat&lt;/a&gt;. (Cryostat is a container-native JVM application that provides a secure API for profiling and monitoring containers with JFR.) This article explains how the new JMX credentials keyring offers an alternative credential management system.&lt;/p&gt; &lt;h2&gt;How the JMX credentials keyring works&lt;/h2&gt; &lt;p&gt;If applications are configured to require JMX authentication for incoming connections, Cryostat must know what those credentials are for any application it needs to connect to. Cryostat connects to the target application in order to start, list, or stop flight recordings, copy JFR data to a local file, get information about JFR event types and templates, etc.&lt;/p&gt; &lt;p&gt;Before Cryostat 2.2, connections to an application through JMX would include an &lt;code&gt;X-JMX-Authorization&lt;/code&gt; header. This header's value would be the JMX credentials required by the target application, so that Cryostat could pass the authentication challenge and connect to the target. The credentials passed in this way weren't stored by Cryostat persistently; they were held in memory just long enough to establish the JMX connection. If you set up your Cryostat installation to use HTTPS and configured your target application to use JMX over SSL/TLS, these credentials were always encrypted while being transmitted.&lt;/p&gt; &lt;p&gt;Cryostat 2.2 adds a keyring to store JMX credentials for your applications. Credentials stored in this way are encrypted at rest using a user-provided passphrase supplied to Cryostat via the &lt;code&gt;CRYOSTAT_JMX_CREDENTIALS_DB_PASSWORD&lt;/code&gt; environment variable.&lt;/p&gt; &lt;p&gt;When attempting to open a JMX connection to a target, Cryostat first checks for the &lt;code&gt;X-JMX-Authorization&lt;/code&gt; header. If there is none, Cryostat checks the keyring database for credentials matching the target, decrypts them using the passphrase, and establishes the JMX connection. Again, if your Cryostat installation is set up with HTTPS and your target uses JMX over SSL/TLS, these JMX credentials are always encrypted in flight, and now they're encrypted at rest within the keyring.&lt;/p&gt; &lt;h2&gt;Advantages of the keyring for microservices&lt;/h2&gt; &lt;p&gt;You might be wondering what I meant by "credentials matching this target" in the previous paragraph. Older versions of Cryostat required the user to define credentials on a per-target basis. Each JMX credential username/password pair was tied to one specific target connection URL. This works fine if your applications are deployed as long-lived "pets" with stable IP addresses, but is not very useful if your applications are deployed as &lt;a href="https://developers.redhat.com/topics/microservices"&gt;microservice&lt;/a&gt; "cattle," where the URL to one specific replica or instance is not particularly meaningful.&lt;/p&gt; &lt;p&gt;For this reason, credentials stored in Cryostat 2.2's JMX keyring are no longer tied to specific target connection URLs. Instead, they reuse the same &lt;em&gt;match expression&lt;/em&gt; concept that was previously introduced for Cryostat &lt;a href="https://developers.redhat.com/articles/2022/05/11/how-build-automated-jfr-rules-cryostat-21s-new-ui"&gt;automated rules&lt;/a&gt;. To recap, match expressions are small snippets of Java-like code, where a representation of a target application is passed and available as a target object reference. The expression evaluates various properties of the target object to determine whether the automated rule or the JMX credentials should apply to that target.&lt;/p&gt; &lt;p&gt;The most reliable way to make sure JMX credentials work using this system is to copy and paste the match expressions from your automated rules definitions and apply them to the JMX credentials, so that the rules and credentials apply to the same set of target applications.&lt;/p&gt; &lt;h2&gt;Additional considerations for using JMX credentials with Cryostat&lt;/h2&gt; &lt;p&gt;Because the connection asking for the JMX credentials challenges the target applications to which it connects, and not Cryostat itself, Cryostat is required to store the whole credential and not just a salted hash of it. Storage operates much like the login keyring you might be familiar with on your personal computer, or a password manager you use for storing your logins for online accounts.&lt;/p&gt; &lt;p&gt;An additional enhancement in Cryostat 2.2 lets you define your JMX credentials &lt;em&gt;after&lt;/em&gt; creating an automated rule. Previously, if an automated rule failed to activate for a target application—due to JMX authentication failure, for example—the rule's actions wouldn't trigger for that target application at all. To make the connection work, after you added the credentials, you had to either delete and recreate the rule or restart the application. Now, if you add JMX credentials to the keyring after the fact, your automated rules will re-trigger and attempt to perform their actions against the relevant target applications.&lt;/p&gt; The post &lt;a href="https://developers.redhat.com/articles/2022/12/07/cryostat-22s-new-jmx-credentials-keyring" title="Cryostat 2.2's new JMX credentials keyring"&gt;Cryostat 2.2's new JMX credentials keyring&lt;/a&gt; appeared first on &lt;a href="https://developers.redhat.com/blog" title="Red Hat Developer"&gt;Red Hat Developer&lt;/a&gt;. &lt;br /&gt;&lt;br /&gt;</summary><dc:creator>Andrew Azores</dc:creator><dc:date>2022-12-07T07:00:01Z</dc:date></entry><entry><title>How to implement single sign-out in Keycloak with Spring Boot</title><link rel="alternate" href="https://developers.redhat.com/articles/2022/12/07/how-implement-single-sign-out-keycloak-spring-boot" /><author><name>Muhammad Edwin</name></author><id>136eb72c-0401-4acd-b078-e1c1c47fa920</id><updated>2022-12-07T07:00:00Z</updated><published>2022-12-07T07:00:00Z</published><summary type="html">&lt;p&gt;Single sign-on is often implemented with &lt;a href="https://www.keycloak.org"&gt;Keycloak&lt;/a&gt;. Few people know that Keycloak can also implement single sign-out, where logging out from one application causes Keycloak to log the user out of other applications. This article demonstrates how to enable single sign-out to clean up active sessions for security purposes. We implement these capabilities in &lt;a href="https://developers.redhat.com/topics/enterprise-java"&gt;Java&lt;/a&gt; and &lt;a href="https://developers.redhat.com/topics/spring-boot"&gt;Spring Boot&lt;/a&gt;, but the principles apply to any language.&lt;/p&gt; &lt;h2&gt;Single sign-on and single sign-out&lt;/h2&gt; &lt;p&gt;Most users are familiar with single sign-on. Once the user logs in to one application, they no longer need to log in when using other applications on the same service. Figure 1 illustrates the benefits of single sign-on with two different applications, each requiring user authentication before gaining access.&lt;/p&gt; &lt;figure class="align-center" role="group"&gt;&lt;div class="rhd-c-figure"&gt; &lt;article class="media media--type-image media--view-mode-article-content"&gt;&lt;div class="field field--name-image field--type-image field--label-hidden field__items"&gt; &lt;a href="https://developers.redhat.com/sites/default/files/signon.png" data-featherlight="image"&gt;&lt;img loading="lazy" src="https://developers.redhat.com/sites/default/files/styles/article_floated/public/signon.png?itok=Yf5Fm0B8" width="600" height="257" alt="A diagram of the single sign-on process." typeof="Image" /&gt;&lt;/a&gt; &lt;/div&gt; &lt;div class="field field--name-field-caption field--type-string field--label-hidden field__items"&gt; &lt;div class="rhd-c-caption field__item"&gt; Figure 1: Single sign-on allows a user to log in just once to access multiple applications. &lt;/div&gt; &lt;/div&gt; &lt;/article&gt;&lt;/div&gt; &lt;figcaption class="rhd-c-caption"&gt;&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;Single sign-on works as follows:&lt;/p&gt; &lt;ol&gt;&lt;li&gt;The user visits Application 01's URL and presses the login button.&lt;/li&gt; &lt;li&gt;The Keycloak login page pops up, prompting the user to log in.&lt;/li&gt; &lt;li&gt;The user is redirected to Application 01's landing page when successfully logged in.&lt;/li&gt; &lt;li&gt;Users who visit Application 02's URL within a reasonable amount of time don't have to log in again.&lt;/li&gt; &lt;/ol&gt;&lt;p&gt;In single sign-out, the user logs out from either application and is logged out from the other automatically, almost immediately. There are several ways to achieve this logout mechanism, such as through &lt;a href="https://www.keycloak.org/docs/latest/server_admin/#_oidc-logout"&gt;OpenID Connect&lt;/a&gt; (OIDC).&lt;/p&gt; &lt;h2&gt;Back-channel vs. front-channel logout&lt;/h2&gt; &lt;p&gt;Before proceeding, you should understand the difference between a back-channel and a front-channel logout. This article implements back-channel logout because it is less subject to problems.&lt;/p&gt; &lt;p&gt;A back-channel logout takes place between Keycloak and its clients. Keycloak detects a user's logout and sends a request containing a logout token to all clients where the user is logged in. The important aspect of back-channel is that it does not rely on a browser. Figure 2 illustrates this operation.&lt;/p&gt; &lt;div class="rhd-c-figure"&gt; &lt;article class="align-center media media--type-image media--view-mode-article-content"&gt;&lt;div class="field field--name-image field--type-image field--label-hidden field__items"&gt; &lt;a href="https://developers.redhat.com/sites/default/files/signout.png" data-featherlight="image"&gt;&lt;img loading="lazy" src="https://developers.redhat.com/sites/default/files/styles/article_floated/public/signout.png?itok=6mSmAsHI" width="600" height="250" alt="Back-channel logout ensures a clean single sign-out by relying on communication between Keycloak and clients." typeof="Image" /&gt;&lt;/a&gt; &lt;/div&gt; &lt;div class="field field--name-field-caption field--type-string field--label-hidden field__items"&gt; &lt;div class="rhd-c-caption field__item"&gt; Figure 2: Back-channel logout ensures a clean single sign-out by relying on communication between Keycloak and clients. &lt;/div&gt; &lt;/div&gt; &lt;/article&gt;&lt;/div&gt; &lt;p&gt; &lt;/p&gt; &lt;p&gt;Back-channel logout operates as follows:&lt;/p&gt; &lt;ol&gt;&lt;li&gt;The user presses the logout button in Application 01.&lt;/li&gt; &lt;li&gt;Application 01 clears out the user's session while informing Keycloak that the user is logging out.&lt;/li&gt; &lt;li&gt;Keycloak invokes Application 02's logout endpoint, asking it to remove the user's session.&lt;/li&gt; &lt;/ol&gt;&lt;p&gt;In contrast, a front-channel logout relies on the browser with an iframe in the browser window that contains the application's logout URL within Keycloak's logout page. Figure 3 illustrates the intended operation.&lt;/p&gt; &lt;div class="rhd-c-figure"&gt; &lt;article class="align-center media media--type-image media--view-mode-article-content"&gt;&lt;div class="field field--name-image field--type-image field--label-hidden field__items"&gt; &lt;a href="https://developers.redhat.com/sites/default/files/multi_1.png" data-featherlight="image"&gt;&lt;img loading="lazy" src="https://developers.redhat.com/sites/default/files/styles/article_floated/public/multi_1.png?itok=-8WVNIe0" width="600" height="264" alt="Front-channel logout relies on the browser to carry out single sign-out." typeof="Image" /&gt;&lt;/a&gt; &lt;/div&gt; &lt;div class="field field--name-field-caption field--type-string field--label-hidden field__items"&gt; &lt;div class="rhd-c-caption field__item"&gt; Figure 3: Front-channel logout relies on the browser to carry out single sign-out. &lt;/div&gt; &lt;/div&gt; &lt;/article&gt;&lt;/div&gt; &lt;p&gt; &lt;/p&gt; &lt;p&gt;Front-channel logout operates as follows:&lt;/p&gt; &lt;ol&gt;&lt;li&gt;The user goes to Keycloak's logout URL and presses the logout button.&lt;/li&gt; &lt;li&gt;The user's browser triggers a logout from the Application 01 URL from an iframe.&lt;/li&gt; &lt;li&gt;Almost simultaneously, the browser triggers a logout from the Application 02 URL from another iframe within the same page.&lt;/li&gt; &lt;/ol&gt;&lt;p&gt;Figure 4 displays a typical user interface for a Keycloak front-channel logout.&lt;/p&gt; &lt;div class="rhd-c-figure"&gt; &lt;article class="align-center media media--type-image media--view-mode-article-content"&gt;&lt;div class="field field--name-image field--type-image field--label-hidden field__items"&gt; &lt;a href="https://developers.redhat.com/sites/default/files/screen.png" data-featherlight="image"&gt;&lt;img loading="lazy" src="https://developers.redhat.com/sites/default/files/styles/article_floated/public/screen.png?itok=FYGeMesc" width="600" height="388" alt="Keycloak displays a logout screen in the browser." typeof="Image" /&gt;&lt;/a&gt; &lt;/div&gt; &lt;div class="field field--name-field-caption field--type-string field--label-hidden field__items"&gt; &lt;div class="rhd-c-caption field__item"&gt; Figure 4: Keycloak displays a logout screen in the browser. &lt;/div&gt; &lt;/div&gt; &lt;/article&gt;&lt;/div&gt; &lt;p&gt; &lt;/p&gt; &lt;p&gt;Various surprises, such as the browser's security policy blocking requests, might happen in a front-channel logout. Therefore, this article implements back-channel logout. We'll see how to configure it and how applications can handle Keycloak's logout API requests. For this example, we use a standalone Keycloak instance listening at port 8080 and a Spring Boot application listening at port 8081.&lt;/p&gt; &lt;h2&gt;Keycloak configuration&lt;/h2&gt; &lt;p&gt;First, you need to open a browser and create a client on Keycloak admin page. Figure 5 displays the screen where you can do this.&lt;/p&gt; &lt;div class="rhd-c-figure"&gt; &lt;article class="align-center media media--type-image media--view-mode-article-content"&gt;&lt;div class="field field--name-image field--type-image field--label-hidden field__items"&gt; &lt;a href="https://developers.redhat.com/sites/default/files/create_3.png" data-featherlight="image"&gt;&lt;img loading="lazy" src="https://developers.redhat.com/sites/default/files/styles/article_floated/public/create_3.png?itok=ob0g6ge2" width="600" height="142" alt="The Clients menu offers a Create button to create a Keycloak client." typeof="Image" /&gt;&lt;/a&gt; &lt;/div&gt; &lt;div class="field field--name-field-caption field--type-string field--label-hidden field__items"&gt; &lt;div class="rhd-c-caption field__item"&gt; Figure 5: The Clients menu offers a Create button to create a Keycloak client. &lt;/div&gt; &lt;/div&gt; &lt;/article&gt;&lt;/div&gt; &lt;p&gt; &lt;/p&gt; &lt;p&gt;Set the Client ID to &lt;code&gt;external-client&lt;/code&gt; and the protocol to &lt;code&gt;openid-connect&lt;/code&gt;. Press the &lt;strong&gt;Save&lt;/strong&gt; button (Figure 6).&lt;/p&gt; &lt;div class="rhd-c-figure"&gt; &lt;article class="align-center media media--type-image media--view-mode-article-content"&gt;&lt;div class="field field--name-image field--type-image field--label-hidden field__items"&gt; &lt;a href="https://developers.redhat.com/sites/default/files/save.png" data-featherlight="image"&gt;&lt;img loading="lazy" src="https://developers.redhat.com/sites/default/files/styles/article_floated/public/save.png?itok=S9jN2XNd" width="600" height="161" alt="After entering basic information, click Save to create a Keycloak client." typeof="Image" /&gt;&lt;/a&gt; &lt;/div&gt; &lt;div class="field field--name-field-caption field--type-string field--label-hidden field__items"&gt; &lt;div class="rhd-c-caption field__item"&gt; Figure 6: After entering basic information, click Save to create a Keycloak client. &lt;/div&gt; &lt;/div&gt; &lt;/article&gt;&lt;/div&gt; &lt;p&gt; &lt;/p&gt; &lt;p&gt;You can now configure the new Keycloak Client. Use the settings in Table 1.&lt;/p&gt; &lt;table cellspacing="0" width="591"&gt;&lt;caption&gt;Table 1: Configuration settings for a Keycloak client.&lt;/caption&gt; &lt;tbody&gt;&lt;tr&gt;&lt;td&gt; &lt;p&gt;Client ID&lt;/p&gt; &lt;/td&gt; &lt;td&gt; &lt;p&gt;external-client&lt;/p&gt; &lt;/td&gt; &lt;/tr&gt;&lt;tr&gt;&lt;td&gt; &lt;p&gt;Enabled&lt;/p&gt; &lt;/td&gt; &lt;td&gt; &lt;p&gt;ON&lt;/p&gt; &lt;/td&gt; &lt;/tr&gt;&lt;tr&gt;&lt;td&gt; &lt;p&gt;Client protocol&lt;/p&gt; &lt;/td&gt; &lt;td&gt; &lt;p&gt;openid-connect&lt;/p&gt; &lt;/td&gt; &lt;/tr&gt;&lt;tr&gt;&lt;td&gt; &lt;p&gt;Access type&lt;/p&gt; &lt;/td&gt; &lt;td&gt; &lt;p&gt;confidential&lt;/p&gt; &lt;/td&gt; &lt;/tr&gt;&lt;tr&gt;&lt;td&gt; &lt;p&gt;Standard flow enabled&lt;/p&gt; &lt;/td&gt; &lt;td&gt; &lt;p&gt;ON&lt;/p&gt; &lt;/td&gt; &lt;/tr&gt;&lt;tr&gt;&lt;td&gt; &lt;p&gt;Direct access grants enabled&lt;/p&gt; &lt;/td&gt; &lt;td&gt; &lt;p&gt;ON&lt;/p&gt; &lt;/td&gt; &lt;/tr&gt;&lt;tr&gt;&lt;td&gt; &lt;p&gt;Valid redirect URIs&lt;/p&gt; &lt;/td&gt; &lt;td&gt; &lt;p&gt;&lt;code&gt;http://localhost:8081/*&lt;/code&gt;&lt;/p&gt; &lt;/td&gt; &lt;/tr&gt;&lt;tr&gt;&lt;td&gt; &lt;p&gt;Base URL&lt;/p&gt; &lt;/td&gt; &lt;td&gt; &lt;p&gt;&lt;code&gt;http://localhost:8081&lt;/code&gt;&lt;/p&gt; &lt;/td&gt; &lt;/tr&gt;&lt;tr&gt;&lt;td&gt; &lt;p&gt;Backchannel logout URL&lt;/p&gt; &lt;/td&gt; &lt;td&gt; &lt;p&gt;&lt;code&gt;http://localhost:8081/sso-logout&lt;/code&gt;&lt;/p&gt; &lt;/td&gt; &lt;/tr&gt;&lt;tr&gt;&lt;td&gt; &lt;p&gt;Backchannel logout session required&lt;/p&gt; &lt;/td&gt; &lt;td&gt; &lt;p&gt;ON&lt;/p&gt; &lt;/td&gt; &lt;/tr&gt;&lt;tr&gt;&lt;td&gt; &lt;p&gt;Backchannel logout revokes offline sessions&lt;/p&gt; &lt;/td&gt; &lt;td&gt; &lt;p&gt;ON&lt;/p&gt; &lt;/td&gt; &lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;&lt;p&gt;Press the &lt;strong&gt;Save&lt;/strong&gt; button to store your configuration.&lt;/p&gt; &lt;h2&gt;Application configuration&lt;/h2&gt; &lt;p&gt;Now create a simple Spring Boot application, starting with a &lt;code&gt;pom.xml&lt;/code&gt; file shown as follows:&lt;/p&gt; &lt;pre&gt; &lt;code class="language-xml"&gt;&lt;?xml version="1.0" encoding="UTF-8"?&gt; &lt;project xmlns="http://maven.apache.org/POM/4.0.0" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd"&gt; &lt;modelVersion&gt;4.0.0&lt;/modelVersion&gt; &lt;groupId&gt;org.edw&lt;/groupId&gt; &lt;artifactId&gt;keycloak-backchannel-logout&lt;/artifactId&gt; &lt;version&gt;1.0-SNAPSHOT&lt;/version&gt; &lt;properties&gt; &lt;maven.compiler.source&gt;11&lt;/maven.compiler.source&gt; &lt;maven.compiler.target&gt;11&lt;/maven.compiler.target&gt; &lt;project.build.sourceEncoding&gt;UTF-8&lt;/project.build.sourceEncoding&gt; &lt;/properties&gt; &lt;parent&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-parent&lt;/artifactId&gt; &lt;version&gt;2.2.6.RELEASE&lt;/version&gt; &lt;relativePath/&gt; &lt;/parent&gt; &lt;dependencyManagement&gt; &lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.keycloak.bom&lt;/groupId&gt; &lt;artifactId&gt;keycloak-adapter-bom&lt;/artifactId&gt; &lt;version&gt;19.0.2&lt;/version&gt; &lt;type&gt;pom&lt;/type&gt; &lt;scope&gt;import&lt;/scope&gt; &lt;/dependency&gt; &lt;/dependencies&gt; &lt;/dependencyManagement&gt; &lt;dependencies&gt; &lt;!-- spring boot --&gt; &lt;dependency&gt; &lt;groupId&gt;org.keycloak&lt;/groupId&gt; &lt;artifactId&gt;keycloak-spring-boot-starter&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-web&lt;/artifactId&gt; &lt;/dependency&gt; &lt;!-- spring security --&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-security&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.keycloak&lt;/groupId&gt; &lt;artifactId&gt;keycloak-spring-security-adapter&lt;/artifactId&gt; &lt;/dependency&gt; &lt;!-- storing session in external db --&gt; &lt;dependency&gt; &lt;groupId&gt;mysql&lt;/groupId&gt; &lt;artifactId&gt;mysql-connector-java&lt;/artifactId&gt; &lt;version&gt;8.0.18&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.session&lt;/groupId&gt; &lt;artifactId&gt;spring-session-jdbc&lt;/artifactId&gt; &lt;version&gt;2.2.6.RELEASE&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-data-jpa&lt;/artifactId&gt; &lt;/dependency&gt; &lt;/dependencies&gt; &lt;build&gt; &lt;plugins&gt; &lt;plugin&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-maven-plugin&lt;/artifactId&gt; &lt;/plugin&gt; &lt;/plugins&gt; &lt;/build&gt; &lt;/project&gt;&lt;/code&gt;&lt;/pre&gt; &lt;p&gt;Also, create an &lt;code&gt;application.properties&lt;/code&gt; file. For this sample application, I'm using MySQL. So I need to put MySQL credentials here:&lt;/p&gt; &lt;pre&gt; &lt;code class="language-ini"&gt;### server port server.port=8081 spring.application.name=Keycloak for Backchannel ### Keycloak Configuration keycloak.auth-server-url=http://localhost:8080/auth/ keycloak.realm=external keycloak.resource=external-client keycloak.public-client=false keycloak.bearer-only=false keycloak.principal-attribute=preferred_username keycloak.credentials.secret=xxxxxxxxx keycloak.use-resource-role-mappings=true keycloak.confidential-port=8081 keycloak.ssl-required=none spring.main.allow-bean-definition-overriding=true logging.level.root=warn logging.level.com.edw=debug server.forward-headers-strategy=NATIVE spring.session.jdbc.flush-mode=on_save spring.session.jdbc.initialize-schema=always spring.datasource.driver-class-name=com.mysql.cj.jdbc.Driver spring.datasource.url=jdbc:mysql://127.0.0.1:3306/db_session spring.datasource.username=root spring.datasource.password=password&lt;/code&gt;&lt;/pre&gt; &lt;p&gt;Next, you need to create a database named &lt;code&gt;db_session&lt;/code&gt; containing two tables. These tables are needed to maintain the application sessions, especially if this application has multiple instances:&lt;/p&gt; &lt;pre&gt; &lt;code class="language-sql"&gt;create table db_session.spring_session ( PRIMARY_ID char(36) not null primary key, SESSION_ID char(36) not null, CREATION_TIME bigint not null, LAST_ACCESS_TIME bigint not null, MAX_INACTIVE_INTERVAL int not null, EXPIRY_TIME bigint not null, PRINCIPAL_NAME varchar(100) null, constraint SPRING_SESSION_IX1 unique (SESSION_ID) ); create index SPRING_SESSION_IX2 on db_session.spring_session (EXPIRY_TIME); create index SPRING_SESSION_IX3 on db_session.spring_session (PRINCIPAL_NAME); create table db_session.spring_session_attributes ( SESSION_PRIMARY_ID char(36) not null, ATTRIBUTE_NAME varchar(200) not null, ATTRIBUTE_BYTES blob not null, primary key (SESSION_PRIMARY_ID, ATTRIBUTE_NAME), constraint SPRING_SESSION_ATTRIBUTES_FK foreign key (SESSION_PRIMARY_ID) references db_session.spring_session (PRIMARY_ID) on delete cascade );&lt;/code&gt;&lt;/pre&gt; &lt;p class="Indent1"&gt;&lt;strong&gt;Note&lt;/strong&gt;: Storing HTTP sessions in your database might negatively impact your application's performance. Therefore, consider other session storing mechanisms for production deployment, such as &lt;a href="https://infinispan.org"&gt;Infinispan&lt;/a&gt;.&lt;/p&gt; &lt;p&gt;Once you set up your database, you can create your application's logout mechanism. But first, you must understand how the Keycloak logout mechanism works and the parameters available for logging out.&lt;/p&gt; &lt;p&gt;Basically, every time a client triggers a logout to Keycloak, Keycloak issues a REST API call to all clients it has registered, instructing the clients to log out their sessions for the corresponding user. The REST API call resembles the following:&lt;/p&gt; &lt;pre&gt; &lt;code class="language-ini"&gt;POST /sso-logout HTTP/1.1 Content-Length: 920 Content-Type: application/x-www-form-urlencoded Host: localhost:8081 Connection: Keep-Alive Accept-Encoding: gzip,deflate logout_token=eyJhbGciOiJSUzI1NiIsInR5cCIgOiAiSldUIiwia2lkIiA6ICJaMHl nYnpDZzJFSWstX0hLbWNtbllodk91RmpaazZ5ZG9mek5BNF8xQnNzIn0.eyJpYXQiOjE 2NjYzNjI4MTksImp0aSI6IjEyYjRmNWY5LWJhZDYtNDQ4MS1hMGUzLWRmMjEzN2U5MmUxY iIsImlzcyI6Imh0dHA6Ly9sb2NhbGhvc3Q6ODA4MC9hdXRoL3JlYWxtcy9leHRlcm5hbCI sImF1ZCI6ImV4dGVybmFsLWNsaWVudCIsInN1YiI6IjRhMzI0ODY0LTkwNDUtNGY2Mi05N jE1LTc5MTdlZDg1NTk1MyIsInR5cCI6IkxvZ291dCIsInNpZCI6ImRkY2ZiZjc0LTYxZG EtNGViNS1iZjBiLTM4MTAyYzdiMzUzNCIsImV2ZW50cyI6eyJodHRwOi8vc2NoZW1hcy 5vcGVuaWQubmV0L2V2ZW50L2JhY2tjaGFubmVsLWxvZ291dCI6e30sInJldm9rZV9vZmZs aW5lX2FjY2VzcyI6dHJ1ZX19.LE34JQnUL2jZKuwlHwgeDnBNnBiacfvJJYpK7_B2bMfMe SUmmOLQ6M3yRlt3nOT4r-AqkStwwFeUA6Io8iuDcQ87eBwoDEYqyJEV9DDduEW8dx8KNMA Tqh_dQFgvq_aqk8P0U2Ap_DjZCCOTtgXTo3solavq2eL2shWLHni5uvSYpY8DLg73SH-n WRp9j2_rjuVGupwSDTmTzftC9zN6_KcURTLgpal9UWr40kSbIa5knSbftcBjzTanLJynR xfX1LckzCine9533h_HQHwqd-LAD3-SFRIkZeMVvv3-BVVubtyXL6VGdB-XLokzRGGh2j d8sgMnEtqNFa8Ih3Iw0A&lt;/code&gt;&lt;/pre&gt; &lt;p&gt;The content of the logout token is a JSON web token (JWT) with a session ID variable (sid) which matches the session ID from the first JWT token granted to a user when they successfully log in.&lt;/p&gt; &lt;p&gt;Now you need a Java class to handle the logout API call. The class that follows captures Keycloak's session ID in your session database and removes the ID when Keycloak calls your logout endpoint:&lt;/p&gt; &lt;pre&gt; &lt;code class="language-java"&gt;@RestController public class IndexController { private Logger logger = LoggerFactory.getLogger(this.getClass()); @Autowired private JdbcTemplate jdbcTemplate; @GetMapping(path = "/") public HashMap index(KeycloakAuthenticationToken authentication, HttpSession httpSession) { SimpleKeycloakAccount account = (SimpleKeycloakAccount) authentication.getDetails(); AccessToken token = account.getKeycloakSecurityContext().getToken(); httpSession.setAttribute(token.getSessionId(), token.getPreferredUsername()); return new HashMap(){{ put("hello", token.getPreferredUsername()); }}; } @PostMapping(path = "/sso-logout", produces = MediaType.APPLICATION_JSON_VALUE) public HashMap logout(@RequestParam("logout_token") String logoutToken) throws Exception { String[] splitString = logoutToken.split("\\."); String body = new String(java.util.Base64.getDecoder().decode(splitString[1])); ObjectMapper mapper = new ObjectMapper(); HashMap bodyMap = mapper.readValue(body, HashMap.class); logger.debug("logging out {}", bodyMap.get("sid")); jdbcTemplate.update("DELETE FROM `spring_session` " + "WHERE `PRIMARY_ID` = (SELECT `PRIMARY_ID` FROM `spring_session_attributes` WHERE `ATTRIBUTE_NAME` = ?)", new Object[] { bodyMap.get("sid") }); return new HashMap(){{ put("status", true); }}; } }&lt;/code&gt;&lt;/pre&gt; &lt;p&gt;Next, set up Keycloak as your default security configuration:&lt;/p&gt; &lt;pre&gt; &lt;code class="language-java"&gt;@KeycloakConfiguration @EnableGlobalMethodSecurity(prePostEnabled = true) public class KeycloakSecurityConfiguration extends KeycloakWebSecurityConfigurerAdapter { @Autowired public void configureGlobal(AuthenticationManagerBuilder auth) throws Exception { KeycloakAuthenticationProvider keycloakAuthenticationProvider = keycloakAuthenticationProvider(); keycloakAuthenticationProvider.setGrantedAuthoritiesMapper(new SimpleAuthorityMapper()); auth.authenticationProvider(keycloakAuthenticationProvider); } @Bean @Override protected SessionAuthenticationStrategy sessionAuthenticationStrategy() { return new RegisterSessionAuthenticationStrategy(new SessionRegistryImpl()); } @Bean public org.keycloak.adapters.KeycloakConfigResolver KeycloakConfigResolver() { return new KeycloakSpringBootConfigResolver(); } @Override protected void configure(HttpSecurity http) throws Exception{ super.configure(http); http .logout() .logoutRequestMatcher(new AntPathRequestMatcher("/logout")) .logoutSuccessUrl("http://localhost:8080/auth/realms/external/protocol/openid-connect/logout?redirect_uri=http://localhost:8081/") .and() .authorizeRequests() .antMatchers("/sso-logout**").permitAll() .antMatchers("/").authenticated() .and().csrf().disable(); } }&lt;/code&gt;&lt;/pre&gt; &lt;p&gt;You are all set. For the complete source code, please visit &lt;a href="https://github.com/edwin/keycloak-backchannel-logout"&gt;my GitHub respository for Keycloak Backchannel Logout&lt;/a&gt;.&lt;/p&gt; &lt;h2&gt;Validating single sign-out&lt;/h2&gt; &lt;p&gt;To see whether your application is handling Keycloak logout requests properly, start by logging in. Open your browser and visit your application's URL (&lt;code&gt;localhost:8081&lt;/code&gt;). It should redirect you to Keycloak's login page (&lt;code&gt;localhost:8080&lt;/code&gt;). A successful login brings you back to your application's landing page, displaying your username.&lt;/p&gt; &lt;p&gt;To log out, open a new tab within the same browser as your application's landing page, and enter the following URL:&lt;/p&gt; &lt;pre&gt; &lt;code class="java"&gt;http://localhost:8080/auth/realms/external/protocol/openid-connect/logout?redirect_uri=http://localhost:8081/&lt;/code&gt;&lt;/pre&gt; &lt;p&gt;This action clears your session ID from Keycloak and your application. If you visit your application URL (&lt;code&gt;localhost:8081&lt;/code&gt;) again, you will have to log in.&lt;/p&gt; &lt;h2&gt;Single sign-out is a Keycloak feature&lt;/h2&gt; &lt;p&gt;This article demonstrated how to implement single sign-out in Java. Applications in any language can handle the REST API call and JWT passed by Keycloak to clean up user sessions.&lt;/p&gt; The post &lt;a href="https://developers.redhat.com/articles/2022/12/07/how-implement-single-sign-out-keycloak-spring-boot" title="How to implement single sign-out in Keycloak with Spring Boot"&gt;How to implement single sign-out in Keycloak with Spring Boot&lt;/a&gt; appeared first on &lt;a href="https://developers.redhat.com/blog" title="Red Hat Developer"&gt;Red Hat Developer&lt;/a&gt;. &lt;br /&gt;&lt;br /&gt;</summary><dc:creator>Muhammad Edwin</dc:creator><dc:date>2022-12-07T07:00:00Z</dc:date></entry></feed>
