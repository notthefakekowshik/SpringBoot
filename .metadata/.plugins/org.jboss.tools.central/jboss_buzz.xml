<?xml version="1.0" encoding="UTF-8"?>
<feed xmlns="http://www.w3.org/2005/Atom" xmlns:dc="http://purl.org/dc/elements/1.1/"><title>JBoss Tools Aggregated Feed</title><link rel="alternate" href="http://tools.jboss.org" /><subtitle>JBoss Tools Aggregated Feed</subtitle><dc:creator>JBoss Tools</dc:creator><entry><title type="html">RESTEasy Releases</title><link rel="alternate" href="https://resteasy.github.io/2022/12/13/resteasy-releases/" /><author><name /></author><id>https://resteasy.github.io/2022/12/13/resteasy-releases/</id><updated>2022-12-13T18:11:11Z</updated><dc:creator /></entry><entry><title>Cryostat 2.2 improvements: Revamped archives views and more</title><link rel="alternate" href="https://developers.redhat.com/articles/2022/12/13/cryostat-22-improvements-revamped-archives-views-and-more" /><author><name>Max Cao</name></author><id>1259d588-d356-48be-a70a-c8b01e86310b</id><updated>2022-12-13T07:00:00Z</updated><published>2022-12-13T07:00:00Z</published><summary type="html">&lt;p&gt;Cryostat is a container-native JVM application that provides a secure API for profiling and monitoring containers with &lt;a href="https://developers.redhat.com/blog/2020/08/25/get-started-with-jdk-flight-recorder-in-openjdk-8u"&gt;JDK Flight Recorder&lt;/a&gt;. In the newest release, &lt;a href="https://developers.redhat.com/articles/2022/11/08/cryostat-22-released-enhanced-java-recording-features"&gt;Cryostat 2.2&lt;/a&gt;, three new and updated views for archived JDK flight recordings managed by Cryostat have been added to the web client, along with new recording filters and enhanced features for recording metadata and custom labels.&lt;/p&gt; &lt;h2&gt;All Targets archived recordings view&lt;/h2&gt; &lt;p&gt;Upon navigating to the Cryostat console tab titled &lt;strong&gt;Archives,&lt;/strong&gt; the first view we see is the &lt;strong&gt;All Targets&lt;/strong&gt; view (Figure 1). From this view, users can see all of their archived recordings from each target JVM as well as any re-uploaded archived recordings in one convenient location.&lt;/p&gt; &lt;figure class="align-center rhd-u-has-filter-caption" role="group"&gt;&lt;div class="rhd-c-figure"&gt; &lt;article class="media media--type-image media--view-mode-article-content"&gt;&lt;div class="field field--name-image field--type-image field--label-hidden field__items"&gt; &lt;a href="https://developers.redhat.com/sites/default/files/fig1_25.png" data-featherlight="image"&gt;&lt;img loading="lazy" src="https://developers.redhat.com/sites/default/files/styles/article_floated/public/fig1_25.png?itok=5LQYDdoz" width="600" height="300" alt="Screenshot of the All Targets archives view" typeof="Image" /&gt;&lt;/a&gt; &lt;/div&gt; &lt;div class="field field--name-field-caption field--type-string field--label-hidden field__items"&gt; &lt;div class="rhd-c-caption field__item"&gt; Figure 1: All Targets archives view &lt;/div&gt; &lt;/div&gt; &lt;/article&gt;&lt;/div&gt; &lt;figcaption class="rhd-c-caption"&gt;Figure 1: All Targets archives view.&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;When we first come upon the view, we can see a card that includes three tabs, one titled &lt;strong&gt;All Targets,&lt;/strong&gt; the second titled &lt;strong&gt;All Archives,&lt;/strong&gt; and the last titled &lt;strong&gt;Uploads.&lt;/strong&gt; By default, the &lt;strong&gt;All Targets&lt;/strong&gt; view will be selected. A checkbox on this view includes the option to &lt;strong&gt;Hide targets with zero recordings.&lt;/strong&gt; By unchecking the box, we can see all targets Cryostat has discovered, with or without any associated archived recordings.&lt;/p&gt; &lt;p&gt;Let's try archiving a recording in one of the targets to see the view in action.&lt;/p&gt; &lt;p&gt;Navigate to the &lt;strong&gt;Recordings&lt;/strong&gt; tab on the Cryostat console and select any target JVM from the dropdown. If any &lt;a href="https://cryostat.io/guides/#store-jmx-credentials"&gt;JMX authorization issues&lt;/a&gt; or &lt;a href="https://cryostat.io/guides/#-add-a-trusted-certificate"&gt;SSL errors&lt;/a&gt; occur, learn to resolve these by reading the guides on the upstream &lt;a href="https://cryostat.io/guides/"&gt;Cryostat website&lt;/a&gt;. Click &lt;strong&gt;Create&lt;/strong&gt; to create a custom flight recording. For now, we can ignore any other new features and simply create a simple recording with these values:&lt;/p&gt; &lt;ul&gt;&lt;li&gt;&lt;strong&gt;Name:&lt;/strong&gt; Cryostat_Demo&lt;/li&gt; &lt;li&gt;&lt;strong&gt;Archive on Stop:&lt;/strong&gt; Unchecked&lt;/li&gt; &lt;li&gt;&lt;strong&gt;Duration:&lt;/strong&gt; 30 Seconds&lt;/li&gt; &lt;li&gt;&lt;strong&gt;Template:&lt;/strong&gt; Profiling&lt;/li&gt; &lt;/ul&gt;&lt;p&gt;Create the recording by clicking the blue &lt;strong&gt;Create&lt;/strong&gt; button. Then archive the created recording by pressing the checkbox next to it and then pressing the &lt;strong&gt;Archive&lt;/strong&gt; button. Navigating to the &lt;strong&gt;Archived Recordings&lt;/strong&gt; tab of the target, we should see the newly archived recording.&lt;/p&gt; &lt;p&gt;Then, going back to the &lt;strong&gt;Archives&lt;/strong&gt; view on the &lt;strong&gt;Console&lt;/strong&gt; tab, we should see the target that we saved the recording from, as well as an updated archived recording count of &lt;code&gt;1&lt;/code&gt; (Figure 2).&lt;/p&gt; &lt;figure class="align-center rhd-u-has-filter-caption" role="group"&gt;&lt;div class="rhd-c-figure"&gt; &lt;article class="media media--type-image media--view-mode-article-content"&gt;&lt;div class="field field--name-image field--type-image field--label-hidden field__items"&gt; &lt;a href="https://developers.redhat.com/sites/default/files/fig2_16.png" data-featherlight="image"&gt;&lt;img loading="lazy" src="https://developers.redhat.com/sites/default/files/styles/article_floated/public/fig2_16.png?itok=Exu6Ukv3" width="600" height="300" alt="Screehshot showing how to view archived recording within nested table from target in the All Targets view" typeof="Image" /&gt;&lt;/a&gt; &lt;/div&gt; &lt;div class="field field--name-field-caption field--type-string field--label-hidden field__items"&gt; &lt;div class="rhd-c-caption field__item"&gt; Figure 2: Viewing archived recording within nested table from target in the All Targets view &lt;/div&gt; &lt;/div&gt; &lt;/article&gt;&lt;/div&gt; &lt;figcaption class="rhd-c-caption"&gt;Figure 2: Viewing archived recording within nested table from target in the All Targets view.&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;Clicking on the dropdown menu next to the target, we can see our newly archived recording along with labels and any actions Cryostat can perform on recordings, such as deleting or downloading it, viewing the associated report, or viewing the recording in Grafana.&lt;/p&gt; &lt;h2&gt;New All Archives archived recordings view&lt;/h2&gt; &lt;p&gt;Now, quickly navigate to the second tab of the &lt;strong&gt;Archives&lt;/strong&gt; section, titled &lt;strong&gt;All Archives.&lt;/strong&gt; After what you did in the previous section, you should now see a single row in a table under the &lt;strong&gt;Directory&lt;/strong&gt; header with a directory name (Figure 3).&lt;/p&gt; &lt;figure class="align-center rhd-u-has-filter-caption" role="group"&gt;&lt;div class="rhd-c-figure"&gt; &lt;article class="media media--type-image media--view-mode-article-content"&gt;&lt;div class="field field--name-image field--type-image field--label-hidden field__items"&gt; &lt;a href="https://developers.redhat.com/sites/default/files/fig3_10.png" data-featherlight="image"&gt;&lt;img loading="lazy" src="https://developers.redhat.com/sites/default/files/styles/article_floated/public/fig3_10.png?itok=fGKPgUWh" width="600" height="300" alt="Screenshot of the All Archives archives view" typeof="Image" /&gt;&lt;/a&gt; &lt;/div&gt; &lt;div class="field field--name-field-caption field--type-string field--label-hidden field__items"&gt; &lt;div class="rhd-c-caption field__item"&gt; Figure 3: All Archives archives view &lt;/div&gt; &lt;/div&gt; &lt;/article&gt;&lt;/div&gt; &lt;figcaption class="rhd-c-caption"&gt;Figure 3: All Archives archives view.&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;The &lt;strong&gt;All Archives&lt;/strong&gt; archived recordings view is a place to view any archived recordings that have been saved to Cryostat's storage. Any archived recording saved from a target JVM through Cryostat or re-uploaded to Cryostat will appear here, under its corresponding directory.&lt;/p&gt; &lt;p&gt;You can perform any actions on recordings within these directories as you could normally, such as &lt;a href="https://cryostat.io/guides/#view-a-recording-in-grafana"&gt;viewing a recording in Grafana&lt;/a&gt;, viewing an &lt;a href="https://cryostat.io/guides/#automated-analysis"&gt;automated analysis report&lt;/a&gt;, or editing labels (more on that later in the article).&lt;/p&gt; &lt;p&gt;If any target JVMs restart or exit when Cryostat is running, you may be unable to find previously saved archived recordings from that source target through the &lt;strong&gt;Recordings&lt;/strong&gt; tab. However, you will always be able to find them here in the &lt;strong&gt;All Archives&lt;/strong&gt; view under the directory table named with the same service URL as the specified target.&lt;/p&gt; &lt;p&gt;Note that if you are upgrading from version 2.1.0 of Cryostat to 2.2.0, any previously saved archived recordings may only appear here in the &lt;strong&gt;All Archives&lt;/strong&gt; view, under a directory named &lt;code&gt;lost&lt;/code&gt;.&lt;/p&gt; &lt;h2&gt;Uploads view&lt;/h2&gt; &lt;p&gt;The final view that has been updated as part of Cryostat 2.2 is the &lt;strong&gt;Uploads&lt;/strong&gt; view. Users may now re-upload and access their JFR recordings through the &lt;strong&gt;Uploads&lt;/strong&gt; tab as part of the &lt;strong&gt;Archives&lt;/strong&gt; view.&lt;/p&gt; &lt;p&gt;Navigating to the &lt;strong&gt;Uploads&lt;/strong&gt; tab on the &lt;strong&gt;All Archives&lt;/strong&gt; view, we can see the &lt;strong&gt;Uploads&lt;/strong&gt; view where we are able to re-upload and interact with any re-uploaded archived JFR recording files by clicking the &lt;strong&gt;+&lt;/strong&gt; icon (Figure 4).&lt;/p&gt; &lt;figure class="align-center rhd-u-has-filter-caption" role="group"&gt;&lt;div class="rhd-c-figure"&gt; &lt;article class="media media--type-image media--view-mode-article-content"&gt;&lt;div class="field field--name-image field--type-image field--label-hidden field__items"&gt; &lt;a href="https://developers.redhat.com/sites/default/files/fig4_8.png" data-featherlight="image"&gt;&lt;img loading="lazy" src="https://developers.redhat.com/sites/default/files/styles/article_floated/public/fig4_8.png?itok=7GggrfK-" width="600" height="300" alt="Screenshot of the Uploads view" typeof="Image" /&gt;&lt;/a&gt; &lt;/div&gt; &lt;div class="field field--name-field-caption field--type-string field--label-hidden field__items"&gt; &lt;div class="rhd-c-caption field__item"&gt; Figure 4: Uploads view &lt;/div&gt; &lt;/div&gt; &lt;/article&gt;&lt;/div&gt; &lt;figcaption class="rhd-c-caption"&gt;Figure 4: Uploads view.&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;From here, we see many of the same actions as before on other views.&lt;/p&gt; &lt;p&gt;For more information on how to re-upload JFR recordings to Cryostat 2.2, see &lt;a href="https://access.redhat.com/documentation/en-us/openjdk/11/html/using_cryostat_to_manage_a_jfr_recording/assembly_archive-jfr-recordings_assembly_security-options#proc-uploading-recording-archive_assembly_archive-jfr-recordings"&gt;the official Red Hat guide&lt;/a&gt;.&lt;/p&gt; &lt;h2&gt;Recording filters&lt;/h2&gt; &lt;p&gt;Another new feature in Cryostat 2.2 is the ability to selectively filter recordings in recording tables. To see this in action, navigate to the &lt;strong&gt;Recordings&lt;/strong&gt; tab, and select a target from the Target Select dropdown menu.&lt;/p&gt; &lt;p&gt;You can see that there is a new dropdown menu and search filter on the toolbar. Clicking the dropdown menu will bring a list of filter categories you can use to better selectively find your recording. You may apply multiple filters across multiple categories.&lt;/p&gt; &lt;p&gt;Let's try using the filtering system here in the Active Recordings table. As before, create a new recording with these configurations:&lt;/p&gt; &lt;ul&gt;&lt;li&gt;&lt;strong&gt;Name:&lt;/strong&gt; Cryostat_Demo_2&lt;/li&gt; &lt;li&gt;&lt;strong&gt;Archive on Stop:&lt;/strong&gt; Unchecked&lt;/li&gt; &lt;li&gt;&lt;strong&gt;Duration:&lt;/strong&gt; 30 Seconds&lt;/li&gt; &lt;li&gt;&lt;strong&gt;Template:&lt;/strong&gt; Profiling&lt;/li&gt; &lt;/ul&gt;&lt;p&gt;On the &lt;strong&gt;Active Recordings&lt;/strong&gt; tab, the first option in our filtering toolbar is the ability to filter selectively on the recording &lt;code&gt;Name&lt;/code&gt;. This is the default option.&lt;/p&gt; &lt;p&gt;Clicking the search bar will bring up a dropdown with the current list of names of recordings within the table. If there are many recordings within the table, you can also type within the bar to narrow down the search.&lt;/p&gt; &lt;p&gt;Click &lt;strong&gt;Cryostat_Demo&lt;/strong&gt; to filter selectively on the recording. Notice how an element shows up with the list of current filters currently selected (Figure 5). You can remove individual filters from the filter group (&lt;code&gt;Name&lt;/code&gt;, in this case), remove entire filter groups, and clear all filters.&lt;/p&gt; &lt;p&gt;Clicking any label of a recording under the &lt;strong&gt;Labels&lt;/strong&gt; column in the recordings table will also use the new filtering system to filter the view to only show recordings that are attached with that label.&lt;/p&gt; &lt;div class="rhd-c-figure"&gt; &lt;article class="align-center media media--type-image media--view-mode-article-content"&gt;&lt;div class="field field--name-image field--type-image field--label-hidden field__items"&gt; &lt;a href="https://developers.redhat.com/sites/default/files/fig5_8.png" data-featherlight="image"&gt;&lt;img loading="lazy" src="https://developers.redhat.com/sites/default/files/styles/article_floated/public/fig5_8.png?itok=vytNUYaw" width="600" height="292" alt="Screenshot showing the recording table with recording name filtering applied" typeof="Image" /&gt;&lt;/a&gt; &lt;/div&gt; &lt;div class="field field--name-field-caption field--type-string field--label-hidden field__items"&gt; &lt;div class="rhd-c-caption field__item"&gt; Figure 5: Recording table with recording name filtering applied. &lt;/div&gt; &lt;/div&gt; &lt;/article&gt;&lt;/div&gt; &lt;p&gt;Before moving on, let's remove all filters by using any of the filter clearing methods listed earlier.&lt;/p&gt; &lt;h2&gt;Enhanced labels&lt;/h2&gt; &lt;p&gt;The final Cryostat 2.2 feature we'll showcase in this article is the enhanced labels, which have been improved for better usability. The biggest change to labels is the ability to bulk edit a batch of labels that may be common to multiple recordings at once.&lt;/p&gt; &lt;p&gt;Let's see one final example. Stay within the &lt;strong&gt;Active Recordings&lt;/strong&gt; tab. Select both recordings created earlier and click the &lt;strong&gt;Edit Labels&lt;/strong&gt; button on the toolbar (Figure 6).&lt;/p&gt; &lt;div class="rhd-c-figure"&gt; &lt;article class="align-center media media--type-image media--view-mode-article-content"&gt;&lt;div class="field field--name-image field--type-image field--label-hidden field__items"&gt; &lt;a href="https://developers.redhat.com/sites/default/files/fig6_5.png" data-featherlight="image"&gt;&lt;img loading="lazy" src="https://developers.redhat.com/sites/default/files/styles/article_floated/public/fig6_5.png?itok=aunjWoqo" width="600" height="300" alt="Screenshot showing the editing recording labels menu" typeof="Image" /&gt;&lt;/a&gt; &lt;/div&gt; &lt;div class="field field--name-field-caption field--type-string field--label-hidden field__items"&gt; &lt;div class="rhd-c-caption field__item"&gt; Figure 6: Editing recording labels menu. &lt;/div&gt; &lt;/div&gt; &lt;/article&gt;&lt;/div&gt; &lt;p&gt;A drawer will appear from the right where you can bulk edit common recording labels between all selected archived recordings. Let's remove a common label and add a new label to both recordings.&lt;/p&gt; &lt;p&gt;Press &lt;strong&gt;Edit&lt;/strong&gt; and remove the &lt;code&gt;template.name&lt;/code&gt; label by pressing the &lt;strong&gt;x&lt;/strong&gt; button next to the label. Then press the &lt;strong&gt;Add Label&lt;/strong&gt; button to create a new label key-value pair. Finally, save the changes.&lt;/p&gt; &lt;p&gt;You have now successfully Bulk-edited labels from several recordings at once.&lt;/p&gt; &lt;h2&gt;Conclusion&lt;/h2&gt; &lt;p&gt;This tutorial walks through the new &lt;strong&gt;Archives&lt;/strong&gt; view and explains the new features for enhanced recording metadata labels and recording filters. To learn how to operate on recordings using these labels, see this previous article on &lt;a href="https://developers.redhat.com/articles/2022/05/17/manage-jfr-across-instances-cryostat-and-graphql"&gt;Managing JFR across instances with Cryostat and GraphQL&lt;/a&gt;. For more information about Cryostat, visit &lt;a href="https://cryostat.io/get-started/"&gt;cryostat.io&lt;/a&gt;. For questions, comments and feedback, feel free to connect with us on &lt;a href="https://github.com/cryostatio"&gt;GitHub&lt;/a&gt; or join our &lt;a href="https://groups.google.com/g/cryostat-development"&gt;mailing list&lt;/a&gt;.&lt;/p&gt; The post &lt;a href="https://developers.redhat.com/articles/2022/12/13/cryostat-22-improvements-revamped-archives-views-and-more" title="Cryostat 2.2 improvements: Revamped archives views and more"&gt;Cryostat 2.2 improvements: Revamped archives views and more&lt;/a&gt; appeared first on &lt;a href="https://developers.redhat.com/blog" title="Red Hat Developer"&gt;Red Hat Developer&lt;/a&gt;. &lt;br /&gt;&lt;br /&gt;</summary><dc:creator>Max Cao</dc:creator><dc:date>2022-12-13T07:00:00Z</dc:date></entry><entry><title type="html">Keycloak 20.0.2 released</title><link rel="alternate" href="https://www.keycloak.org/2022/12/keycloak-2002-released" /><author><name /></author><id>https://www.keycloak.org/2022/12/keycloak-2002-released</id><updated>2022-12-13T00:00:00Z</updated><content type="html">To download the release go to . MIGRATION FROM 19.0 Before you upgrade remember to backup your database. If you are not on the previous release refer to for a complete list of migration changes. ALL RESOLVED ISSUES ENHANCEMENTS * Expiration for Admin Events keycloak BUGS * KC Operator Test WatchedSecretsTest.testSecretsAreWatched is unstable keycloak operator * Error in Core? ( Clients Client details Dedicated scopes): Cannot read properties of undefined (reading 'helpText') keycloak admin/ui * NPE in theme.getName() via getMainPage keycloak core * Failed to run scheduled task ClearExpiredAdminEvents Oracle keycloak storage * Flaky test: OpenshiftClientStorageTest.testCodeGrantFlowWithServiceAccountUsingOAuthRedirectReference keycloak testsuite * SAMLFilterServletAdapterTest fails on Oracle keycloak storage * Internal pipelines don't tests run for OracleDB or other database keycloak storage * clientID are base64 encoded in state uri param with non URI friendly base64 keycloak storage UPGRADING Before you upgrade remember to backup your database and check the for anything that may have changed.</content><dc:creator /></entry><entry><title>Kubernetes-native inner loop development with Quarkus</title><link rel="alternate" href="https://developers.redhat.com/articles/2022/12/12/kubernetes-native-inner-loop-development-quarkus" /><author><name>Eric Deandrea</name></author><id>61ab4bf3-0be1-494b-8c0d-451db908fb92</id><updated>2022-12-12T07:00:00Z</updated><published>2022-12-12T07:00:00Z</published><summary type="html">&lt;p&gt;&lt;a href="https://developers.redhat.com/topics/microservices"&gt;Microservices&lt;/a&gt; today are often deployed on a platform such as &lt;a href="https://developers.redhat.com/topics/kubernetes"&gt;Kubernetes&lt;/a&gt;, which orchestrates the deployment and management of containerized applications. Microservices, however, don't exist in a vacuum. They typically communicate with other services, such as databases, message brokers, or other microservices. Therefore, an application usually consists of multiple services that form a complete solution.&lt;/p&gt; &lt;p&gt;But, as a developer, how do you develop and test an individual microservice that is part of a larger system? This article examines some common &lt;em&gt;inner-loop&lt;/em&gt; development cycle challenges and shows how Quarkus and other technologies help solve some of these challenges.&lt;/p&gt; &lt;h2&gt;What is the inner loop?&lt;/h2&gt; &lt;p&gt;Almost all software development is iterative. T&lt;span&gt;he &lt;em&gt;inner loop&lt;/em&gt; contains everything that happens on a developer's machine &lt;/span&gt;&lt;em&gt;before&lt;/em&gt;&lt;span&gt; committing code into version control. The inner loop is where a developer writes code, builds and tests it, and perhaps runs the code locally. In today's world, the inner loop could also include multiple commits to a &lt;/span&gt;&lt;a href="https://docs.github.com/en/pull-requests/collaborating-with-pull-requests/proposing-changes-to-your-work-with-pull-requests/about-pull-requests"&gt;Git pull request&lt;/a&gt;&lt;span&gt;, where a developer may commit multiple times against a specific feature until that feature is deemed complete.&lt;/span&gt;&lt;/p&gt; &lt;p class="Indent1"&gt;&lt;strong&gt;Note:&lt;/strong&gt; The word &lt;em&gt;local&lt;/em&gt; is also up for debate in industry today as more and more remote development environments, such as &lt;a href="https://developers.redhat.com/developer-sandbox/ide"&gt;Red Hat OpenShift Dev Spaces&lt;/a&gt;, &lt;a href="https://gitpod.io"&gt;Gitpod&lt;/a&gt;, and &lt;a href="https://github.com/features/codespaces"&gt;GitHub Codespaces&lt;/a&gt; are available. This article does not differentiate between a developer machine and any of these kinds of environments. They are all viewed as &lt;em&gt;local&lt;/em&gt; in this article.&lt;/p&gt; &lt;p&gt;&lt;em&gt;Inner loop&lt;/em&gt; shifts to &lt;em&gt;outer loop&lt;/em&gt; when code reaches a point in source control where it needs to be built, tested, scanned, and ultimately deployed by automated &lt;a href="https://developers.redhat.com/topics/ci-cd"&gt;continuous integration and deployment&lt;/a&gt; (CI/CD) processes. Figure 1 illustrates a simple inner loop and outer loop.&lt;/p&gt; &lt;div class="rhd-c-figure"&gt; &lt;article class="align-center media media--type-image media--view-mode-article-content"&gt;&lt;div class="field field--name-image field--type-image field--label-hidden field__items"&gt; &lt;a href="https://developers.redhat.com/sites/default/files/fig1_24.png" data-featherlight="image"&gt;&lt;img loading="lazy" src="https://developers.redhat.com/sites/default/files/styles/article_floated/public/fig1_24.png?itok=LsPqCLBm" width="600" height="320" alt="Diagram showing that the inner loop takes place on a developer's local machine, whereas the outer loop takes place within CI/CD processes." typeof="Image" /&gt;&lt;/a&gt; &lt;/div&gt; &lt;div class="field field--name-field-caption field--type-string field--label-hidden field__items"&gt; &lt;div class="rhd-c-caption field__item"&gt; Figure 1: The inner loop takes place on a developer's local machine, whereas the outer loop takes place within CI/CD processes. &lt;/div&gt; &lt;/div&gt; &lt;/article&gt;&lt;/div&gt; &lt;h2&gt;Challenges of inner loop development&lt;/h2&gt; &lt;p&gt;Developing a single microservice in isolation is challenging enough without worrying about additional downstream services. How do you run a microservice in isolation on your local machine if it depends on other services for it to function properly?&lt;/p&gt; &lt;p&gt;Using various mocking techniques, you can to some extent get around the absence of required services when writing and running tests. Mocking techniques generally work great for testing. You can also use in-memory replacements for required services, such as an &lt;a href="https://www.h2database.com"&gt;H2 database&lt;/a&gt; instead of a separate database instance. Beyond that, if you want or need to run the application locally, you need a better solution.&lt;/p&gt; &lt;p&gt;Of course, you could &lt;em&gt;try&lt;/em&gt; to reproduce your application's entire environment on your development machine. But even if you could, would you really want to? Do you think a developer at Twitter or Netflix could reproduce their environment on their development machine? Figure 2 shows the complexity of their architectures. &lt;a href="https://eng.lyft.com/scaling-productivity-on-microservices-at-lyft-part-1-a2f5d9a77813"&gt;Lyft also tried this approach&lt;/a&gt; and found it wasn't feasible or scalable.&lt;/p&gt; &lt;div class="rhd-c-figure"&gt; &lt;article class="align-center media media--type-image media--view-mode-article-content"&gt;&lt;div class="field field--name-image field--type-image field--label-hidden field__items"&gt; &lt;a href="https://developers.redhat.com/sites/default/files/fig2.jpeg" data-featherlight="image"&gt;&lt;img loading="lazy" src="https://developers.redhat.com/sites/default/files/styles/article_floated/public/fig2.jpeg?itok=a2zAHnqd" width="600" height="264" alt="Diagram illustrating that major services such as Netflix and Twitter can easy have more than 500 microservices." typeof="Image" /&gt;&lt;/a&gt; &lt;/div&gt; &lt;span class="field field--name-field-source-url field--type-string field--label-hidden field__items"&gt; https://future.com/the-case-for-developer-experience &lt;/span&gt; &lt;div class="field field--name-field-caption field--type-string field--label-hidden field__items"&gt; &lt;div class="rhd-c-caption field__item"&gt; Figure 2: Major services such as Netflix and Twitter can easy have more than 500 microservices. &lt;/div&gt; &lt;/div&gt; &lt;/article&gt;&lt;/div&gt; &lt;h2&gt;Container-based inner loop solutions&lt;/h2&gt; &lt;p&gt;Using containers can help speed up and improve the inner loop development lifecycle. Containers can help isolate and provide a local instance of a dependent service. We'll look at a few popular tools and technologies for the inner loop.&lt;/p&gt; &lt;h3&gt;Docker Compose&lt;/h3&gt; &lt;p&gt;One common pattern is to use &lt;a href="https://docs.docker.com/compose"&gt;Docker Compose&lt;/a&gt; to run some of your microservice's dependent services (databases, message brokers, etc.) locally while you run, debug, and test your microservice. With Docker Compose, you define a set of containerized services that provide the capabilities required by your microservice. You can easily start, stop, and view logs from these containerized services.&lt;/p&gt; &lt;p&gt;However, there are a few downsides to using Docker Compose. First, you must maintain your Docker Compose configuration independently of your application's code. You must remember to make changes to the Docker Compose configuration as your application evolves, sometimes duplicating configuration between your application and your Docker Compose configuration.&lt;/p&gt; &lt;p&gt;Second, you are locked into using the Docker binary. For Windows and macOS users, &lt;a href="https://www.docker.com/pricing/faq"&gt;Docker Desktop is no longer free for many non-individual users&lt;/a&gt;. You are also prevented from using other container runtimes, such as &lt;a href="https://podman.io"&gt;Podman&lt;/a&gt;. &lt;a href="https://www.redhat.com/sysadmin/podman-docker-compose"&gt;Podman does support Docker Compose&lt;/a&gt;, but it doesn't support everything you can do with Docker Compose, especially on non-Linux machines.&lt;/p&gt; &lt;h3&gt;Testcontainers&lt;/h3&gt; &lt;p&gt;&lt;a href="https://www.testcontainers.org"&gt;Testcontainers&lt;/a&gt; is an excellent library for creating and managing container instances for various services when applications run tests. It provides lightweight, throwaway instances of common databases, message brokers, or anything else that can run in a container.&lt;/p&gt; &lt;p&gt;But Testcontainers is only a library. That means an application must incorporate it and &lt;em&gt;do&lt;/em&gt; something with it to realize its benefits. Generally speaking, applications that use Testcontainers do so when executing unit or integration tests, but not in production. A developer generally won't include the library in the application's dependencies because Testcontainers doesn't belong as a dependency when the application is deployed into a &lt;em&gt;real&lt;/em&gt; environment with &lt;em&gt;real&lt;/em&gt; services.&lt;/p&gt; &lt;h3&gt;Quarkus&lt;/h3&gt; &lt;p&gt;&lt;a href="https://developers.redhat.com/products/quarkus"&gt;Quarkus&lt;/a&gt; is a Kubernetes-native Java application framework focusing on more than just feature sets. In addition to enabling fast startup times and low memory footprints compared to traditional Java applications, Quarkus ensures that every feature works well, with little to no configuration, in a highly intuitive way. The framework aims to make it trivial to develop simple things and easy to develop more complex ones. Beyond simply working well, Quarkus aims to bring &lt;a href="https://quarkus.io/developer-joy"&gt;Developer Joy&lt;/a&gt;, specifically targeting the inner loop development lifecycle.&lt;/p&gt; &lt;h4&gt;Dev mode&lt;/h4&gt; &lt;p&gt;The first part of the Quarkus Developer Joy story, live coding via &lt;a href="https://quarkus.io/guides/maven-tooling#dev-mode"&gt;Quarkus dev mode&lt;/a&gt;, improves and expedites the inner loop development process. When Quarkus dev mode starts, Quarkus automatically reflects code changes within the running application. Therefore, Quarkus combines the &lt;strong&gt;Write Code&lt;/strong&gt;, &lt;strong&gt;Build&lt;/strong&gt;, and &lt;strong&gt;Deploy/Run&lt;/strong&gt; steps of Figure 1's inner loop into a single step. Simply write code, interact with your application, and see your changes running with little to no delay.&lt;/p&gt; &lt;h4&gt;Dev Services&lt;/h4&gt; &lt;p&gt;A second part of the Quarkus Developer Joy story, &lt;a href="https://quarkus.io/guides/dev-services"&gt;Quarkus Dev Services&lt;/a&gt;, automatically provisions and configures supporting services, such as databases, message brokers, and more. When you run Quarkus in dev mode or execute tests, Quarkus examines all the extensions present. Quarkus then automatically starts any unconfigured and relevant service and configures the application to use that service.&lt;/p&gt; &lt;p&gt;Quarkus Dev Services uses Testcontainers, which we've already discussed, but in a manner completely transparent to the developer. The developer does not need to add the Testcontainers libraries, perform any integration or configuration, or write any code. Furthermore, Dev Services does not affect the application when it is deployed into a real environment with real services.&lt;/p&gt; &lt;p&gt;Additionally, if you have multiple Quarkus applications on your local machine and run them in dev mode, by default, Dev Services attempts to share the services between the applications. Sharing services is beneficial if you work on more than one application that uses the same service, such as a message broker.&lt;/p&gt; &lt;p&gt;Let's use the &lt;a href="https://github.com/quarkusio/quarkus-super-heroes"&gt;Quarkus Superheroes sample application&lt;/a&gt; as an example. The application consists of several microservices that together form an extensive system. Some microservices communicate synchronously via REST. Others are event-driven, producing and consuming events to and from &lt;a href="https://kafka.apache.org"&gt;Apache Kafka&lt;/a&gt;. Some microservices are reactive, whereas others are traditional. All the microservices produce metrics consumed by &lt;a href="https://prometheus.io"&gt;Prometheus&lt;/a&gt; and export tracing information to &lt;a href="https://opentelemetry.io"&gt;OpenTelemetry&lt;/a&gt;.&lt;/p&gt; &lt;p&gt;The source code for the application is on &lt;a href="https://github.com/quarkusio/quarkus-super-heroes"&gt;GitHub&lt;/a&gt; under an Apache 2.0 license. The system's architecture is shown in Figure 3.&lt;/p&gt; &lt;figure class="align-center rhd-u-has-filter-caption" role="group"&gt;&lt;div class="rhd-c-figure"&gt; &lt;article class="media media--type-image media--view-mode-article-content"&gt;&lt;div class="field field--name-image field--type-image field--label-hidden field__items"&gt; &lt;a href="https://developers.redhat.com/sites/default/files/fig3_9.png" data-featherlight="image"&gt;&lt;img loading="lazy" src="https://developers.redhat.com/sites/default/files/styles/article_floated/public/fig3_9.png?itok=wilWXzNN" width="600" height="686" alt="Architectural diagram of the Superheroes application, which has many microservices, some with dependencies." typeof="Image" /&gt;&lt;/a&gt; &lt;/div&gt; &lt;div class="field field--name-field-caption field--type-string field--label-hidden field__items"&gt; &lt;div class="rhd-c-caption field__item"&gt; Figure 3: The Superheroes application has many microservices, some with dependencies. &lt;/div&gt; &lt;/div&gt; &lt;/article&gt;&lt;/div&gt; &lt;figcaption class="rhd-c-caption"&gt;Figure 3: The Quarkus Superheroes application has many microservices and additional dependent services.&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;In the Quarkus Superheroes sample application, you could start both the &lt;code&gt;rest-fights&lt;/code&gt; and &lt;code&gt;event-statistics&lt;/code&gt; services locally in dev mode. The &lt;code&gt;rest-fights&lt;/code&gt; dev mode starts a &lt;a href="https://www.mongodb.com"&gt;MongoDB&lt;/a&gt; container instance, an &lt;a href="https://www.apicur.io/registry"&gt;Apicurio Registry&lt;/a&gt; container instance, and an &lt;a href="https://kafka.apache.org"&gt;Apache Kafka&lt;/a&gt; container instance. The &lt;code&gt;event-statistics&lt;/code&gt; service also requires an Apicurio Registry instance and an Apache Kafka instance, so the instance started by the &lt;code&gt;rest-fights&lt;/code&gt; dev mode will be discovered and used by the &lt;code&gt;event-statistics&lt;/code&gt; service.&lt;/p&gt; &lt;h4&gt;Continuous testing&lt;/h4&gt; &lt;p&gt;A third part of the Quarkus Developer Joy story, &lt;a href="https://quarkus.io/guides/continuous-testing"&gt;continuous testing&lt;/a&gt;, provides instant feedback on code changes by immediately executing affected tests in the background. Quarkus detects which tests cover which code and reruns only the tests relevant to that code as you change it. Quarkus continuous testing combines testing with dev mode and Dev Services into a powerful inner loop productivity feature, shrinking all of Figure 1's inner loop lifecycle steps into a single step.&lt;/p&gt; &lt;h2&gt;Other inner loop solutions&lt;/h2&gt; &lt;p&gt;The solutions we've outlined thus far are extremely helpful with local inner loop development, especially if your microservice requires only a small set of other services, such as a database, or a database and message broker.&lt;/p&gt; &lt;p&gt;But when there are &lt;em&gt;lots&lt;/em&gt; of dependent services, trying to replicate them all on a local machine probably won't work well, if at all.&lt;/p&gt; &lt;p&gt;So what do you do? How do you get the speed and agility of inner loop development for an application when it depends on other services that you either &lt;em&gt;can't&lt;/em&gt; or &lt;em&gt;don't want to&lt;/em&gt; run locally?&lt;/p&gt; &lt;p&gt;One solution could be to manage an environment of &lt;em&gt;shared&lt;/em&gt; services. Each developer would then configure those services in their local setup, careful not to commit the configuration into source control.&lt;/p&gt; &lt;p&gt;Another solution could be to use Kubernetes, giving each developer a namespace where they can deploy what they need. The developer could then deploy the services and configure their local application to use them.&lt;/p&gt; &lt;p&gt;Both of these solutions &lt;em&gt;could&lt;/em&gt; work, but in reality, they usually end up with a problem: The microservice the developer is working on is &lt;em&gt;somewhere&lt;/em&gt; in the graph of services of an overall system. How does a developer trigger the microservice they care about to get called as part of a larger request or flow?&lt;/p&gt; &lt;p&gt;Wouldn't a better solution be to run the application locally, but make the larger system &lt;em&gt;think&lt;/em&gt; the application is actually deployed somewhere?&lt;/p&gt; &lt;p&gt;This kind of remote + local development model is becoming known as &lt;em&gt;remocal&lt;/em&gt;. It is an extremely powerful way to get immediate feedback during your inner loop development cycle while ensuring your application behaves properly in an environment that is close to or matches production.&lt;/p&gt; &lt;h3&gt;Quarkus remote development&lt;/h3&gt; &lt;p&gt;Another part of the Quarkus Developer Joy story, &lt;a href="https://quarkus.io/guides/maven-tooling#remote-development-mode"&gt;remote development&lt;/a&gt;, enables a developer to deploy an application into a remote environment and run Quarkus dev mode in that environment while doing live coding locally. Quarkus immediately synchronizes code changes to the remotely deployed instance.&lt;/p&gt; &lt;p&gt;Quarkus remote development allows a developer to develop the application in the same environment it will run in while having access to the same services it will have access to. Additionally, this capability greatly reduces the inner feedback loop while alleviating the "works on my machine" problem. Remote development also allows for quick and easy prototyping of new features and capabilities. Figure 4 illustrates how the remote development mode works.&lt;/p&gt; &lt;div class="rhd-c-figure"&gt; &lt;article class="align-center media media--type-image media--view-mode-article-content"&gt;&lt;div class="field field--name-image field--type-image field--label-hidden field__items"&gt; &lt;a href="https://developers.redhat.com/sites/default/files/dev_0.png" data-featherlight="image"&gt;&lt;img loading="lazy" src="https://developers.redhat.com/sites/default/files/styles/article_floated/public/dev_0.png?itok=68N800JI" width="600" height="353" alt="Quarkus remote dev mode incrementally synchronizes local code changes with a remote Quarkus application." typeof="Image" /&gt;&lt;/a&gt; &lt;/div&gt; &lt;div class="field field--name-field-caption field--type-string field--label-hidden field__items"&gt; &lt;div class="rhd-c-caption field__item"&gt; Figure 4: Quarkus remote dev mode incrementally synchronizes local code changes with a remote Quarkus application. &lt;/div&gt; &lt;/div&gt; &lt;/article&gt;&lt;/div&gt; &lt;p&gt;First, the application is deployed to Kubernetes, a virtual machine, a container, or just some Java virtual machine (JVM) somewhere. Once running, the developer runs the remote development mode on their local machine, connecting their local machine to the remote instance.&lt;/p&gt; &lt;p&gt;From there, development is just like live coding in Quarkus dev mode. As the developer makes code changes, Quarkus automatically compiles and pushes the changes to the remote instance.&lt;/p&gt; &lt;p&gt;Let's continue with the Quarkus Superheroes example from before. Let's assume the entire system is deployed into a Kubernetes cluster. Let's also assume you want to make changes to the &lt;code&gt;rest-fights&lt;/code&gt; microservice.&lt;/p&gt; &lt;p&gt;As shown in Figure 5, you start the &lt;code&gt;rest-fights&lt;/code&gt; microservice in remote dev mode on your local machine. The &lt;code&gt;rest-fights&lt;/code&gt; application running on the cluster connects to the MongoDB, Apicurio Registry, and Apache Kafka instances on the Kubernetes cluster.&lt;/p&gt; &lt;figure class="align-center rhd-u-has-filter-caption" role="group"&gt;&lt;div class="rhd-c-figure"&gt; &lt;article class="media media--type-image media--view-mode-article-content"&gt;&lt;div class="field field--name-image field--type-image field--label-hidden field__items"&gt; &lt;a href="https://developers.redhat.com/sites/default/files/fig5_7.png" data-featherlight="image"&gt;&lt;img loading="lazy" src="https://developers.redhat.com/sites/default/files/styles/article_floated/public/fig5_7.png?itok=fIwEDwZe" width="600" height="379" alt="Diagram showing changes to the local application during remote development send updates continuously to the services in the cloud." typeof="Image" /&gt;&lt;/a&gt; &lt;/div&gt; &lt;div class="field field--name-field-caption field--type-string field--label-hidden field__items"&gt; &lt;div class="rhd-c-caption field__item"&gt; Figure 5: Changes to the local application during remote development send updates continuously to the services in the cloud. &lt;/div&gt; &lt;/div&gt; &lt;/article&gt;&lt;/div&gt; &lt;figcaption class="rhd-c-caption"&gt;Figure 5: Changes to the local application in remote development mode continuously send updates to the remote instance.&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;You can then interact with the system through its user interface. Quarkus incrementally synchronizes the changes with the remote instance on the Kubernetes cluster as you make changes to the &lt;code&gt;rest-fights&lt;/code&gt; microservice. If you want, you could even use breakpoints within your IDE on your local machine to assist with debugging.&lt;/p&gt; &lt;h3&gt;Skupper&lt;/h3&gt; &lt;p&gt;&lt;a href="https://skupper.io"&gt;Skupper&lt;/a&gt; is a layer 7 service interconnect that enables secure communication across Kubernetes clusters without VPNs or special firewall rules. Using Skupper, an application can span multiple cloud providers, data centers, and regions. Figure 6 shows a high-level view of Skupper.&lt;/p&gt; &lt;figure class="align-center rhd-u-has-filter-caption" role="group"&gt;&lt;div class="rhd-c-figure"&gt; &lt;article class="media media--type-image media--view-mode-article-content"&gt;&lt;div class="field field--name-image field--type-image field--label-hidden field__items"&gt; &lt;a href="https://developers.redhat.com/sites/default/files/overview.png" data-featherlight="image"&gt;&lt;img loading="lazy" src="https://developers.redhat.com/sites/default/files/styles/article_floated/public/overview.png?itok=RXxczIfj" width="600" height="222" alt="Skupper connects services on different sites using routers at network layer 7." typeof="Image" /&gt;&lt;/a&gt; &lt;/div&gt; &lt;div class="field field--name-field-caption field--type-string field--label-hidden field__items"&gt; &lt;div class="rhd-c-caption field__item"&gt; Figure 6: Skupper connects services on different sites using routers at network layer 7. &lt;/div&gt; &lt;/div&gt; &lt;/article&gt;&lt;/div&gt; &lt;figcaption class="rhd-c-caption"&gt;Figure 6: Logically, Skupper connects services on different sites together to exist as a single site.&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;With Skupper, you can create a distributed application comprised of microservices running in different namespaces within different Kubernetes clusters. Services exposed to Skupper are subsequently exposed to each namespace as if they existed in the namespace. Skupper creates proxy endpoints to make a service available within each of the namespaces where it is installed. Figure 7 shows a logical view of this architecture.&lt;/p&gt; &lt;div class="rhd-c-figure"&gt; &lt;article class="align-center media media--type-image media--view-mode-article-content"&gt;&lt;div class="field field--name-image field--type-image field--label-hidden field__items"&gt; &lt;a href="https://developers.redhat.com/sites/default/files/view_0.png" data-featherlight="image"&gt;&lt;img loading="lazy" src="https://developers.redhat.com/sites/default/files/styles/article_floated/public/view_0.png?itok=w67RqnD9" width="600" height="248" alt="Logically, Skupper can span multiple Kubernetes clusters and make remote services appear as local ones." typeof="Image" /&gt;&lt;/a&gt; &lt;/div&gt; &lt;div class="field field--name-field-caption field--type-string field--label-hidden field__items"&gt; &lt;div class="rhd-c-caption field__item"&gt; Figure 7: Logically, Skupper can span multiple Kubernetes clusters and make remote services appear as local ones. &lt;/div&gt; &lt;/div&gt; &lt;/article&gt;&lt;/div&gt; &lt;p&gt;Why do we mention Skupper in an article about Kubernetes native inner loop development? Because in addition to bridging applications across Kubernetes clusters, a Skupper proxy can run on any machine, enabling bidirectional communication between the machine and the other Kubernetes clusters.&lt;/p&gt; &lt;p&gt;Logically, this is like a local machine inserted into the middle of a set of Kubernetes clusters. Services exposed to Skupper on the clusters can discover services exposed to the Skupper proxy on the local machine and vice versa.&lt;/p&gt; &lt;p&gt;Skupper can make our Quarkus Superheroes example even more interesting, taking it further from the remote development scenario we described earlier.&lt;/p&gt; &lt;p&gt;With Skupper, rather than continuously synchronizing changes to the &lt;code&gt;rest-fights&lt;/code&gt; service from a local instance to a remote instance, you could completely replace the remote &lt;code&gt;rest-fights&lt;/code&gt; instance with a local instance running Quarkus dev mode and continuous testing.&lt;/p&gt; &lt;p&gt;Skupper would then redirect traffic on the Kubernetes cluster &lt;em&gt;into&lt;/em&gt; the &lt;code&gt;rest-fights&lt;/code&gt; service running on your local machine. Any outgoing requests made by the &lt;code&gt;rest-fights&lt;/code&gt; service, such as connections to the MongoDB, Apicurio registry, and Apache Kafka instances, and even the &lt;code&gt;rest-heroes&lt;/code&gt; and &lt;code&gt;rest-villains&lt;/code&gt; services, would then be redirected back to the Kubernetes cluster. Figure 8 shows a logical view of what this architecture might look like.&lt;/p&gt; &lt;div class="rhd-c-figure"&gt; &lt;article class="align-center media media--type-image media--view-mode-article-content"&gt;&lt;div class="field field--name-image field--type-image field--label-hidden field__items"&gt; &lt;a href="https://developers.redhat.com/sites/default/files/fig8_0.png" data-featherlight="image"&gt;&lt;img loading="lazy" src="https://developers.redhat.com/sites/default/files/styles/article_floated/public/fig8_0.png?itok=W2SZheJC" width="512" height="592" alt="Diagram showing that, logically, Skupper can make it look like a local developer machine is inside a Kubernetes cluster." typeof="Image" /&gt;&lt;/a&gt; &lt;/div&gt; &lt;div class="field field--name-field-caption field--type-string field--label-hidden field__items"&gt; &lt;div class="rhd-c-caption field__item"&gt; Figure 8: Logically, Skupper can make it look like a local developer machine is inside a Kubernetes cluster. &lt;/div&gt; &lt;/div&gt; &lt;/article&gt;&lt;/div&gt; &lt;p&gt;You could even use Quarkus dev services to allow the &lt;code&gt;rest-fights&lt;/code&gt; microservice to provide its own local MongoDB instance rather than using the instance on the cluster, yet continue to let traffic to Kafka flow onto the cluster. This setup would enable other Kafka consumers listening on the same topic to continue functioning.&lt;/p&gt; &lt;p&gt;In this scenario, Quarkus continuously runs the tests of the &lt;code&gt;rest-fights&lt;/code&gt; microservice while a developer makes live code changes, all while traffic is continually flowing through the whole system on the Kubernetes cluster. The services could even be spread out to other Kubernetes clusters on different cloud providers in other regions of the world while traffic continues to flow through a developer's local machine.&lt;/p&gt; &lt;h2&gt;A better developer experience, whether local or distributed&lt;/h2&gt; &lt;p&gt;Parts &lt;a href="https://eng.lyft.com/scaling-productivity-on-microservices-at-lyft-part-2-optimizing-for-fast-local-development-9f27a98b47ee"&gt;two&lt;/a&gt; and &lt;a href="https://eng.lyft.com/scaling-productivity-on-microservices-at-lyft-part-3-extending-our-envoy-mesh-with-staging-fdaafafca82f"&gt;three&lt;/a&gt; of the previously mentioned &lt;a href="https://eng.lyft.com/scaling-productivity-on-microservices-at-lyft-part-1-a2f5d9a77813"&gt;article series at Lyft&lt;/a&gt; show Lyft's approach to solving this problem, albeit using different technologies. As more and more services came to life, Lyft saw that what they were doing wasn't scaling and that they therefore needed a kind of "remocal" environment.&lt;/p&gt; &lt;p&gt;Quarkus was designed with many of these Developer Joy characteristics in mind. Quarkus helps developers iterate faster and contains built-in capabilities that alleviate many of these challenges and shorten the development lifecycles. Developers can focus on writing code.&lt;/p&gt; The post &lt;a href="https://developers.redhat.com/articles/2022/12/12/kubernetes-native-inner-loop-development-quarkus" title="Kubernetes-native inner loop development with Quarkus"&gt;Kubernetes-native inner loop development with Quarkus&lt;/a&gt; appeared first on &lt;a href="https://developers.redhat.com/blog" title="Red Hat Developer"&gt;Red Hat Developer&lt;/a&gt;. &lt;br /&gt;&lt;br /&gt;</summary><dc:creator>Eric Deandrea</dc:creator><dc:date>2022-12-12T07:00:00Z</dc:date></entry><entry><title type="html">Kogito 1.31.0 released!</title><link rel="alternate" href="https://blog.kie.org/2022/12/kogito-1-31-0-released.html" /><author><name>Cristiano Nicolai</name></author><id>https://blog.kie.org/2022/12/kogito-1-31-0-released.html</id><updated>2022-12-12T01:49:18Z</updated><content type="html">We are glad to announce that the Kogito 1.31.0 release is now available! This goes hand in hand with , release. From a feature point of view, we have included a series of new features and bug fixes, including: * Quarkus 2.14 integration * First alpha version of the * New OpenAPI Callback example within Serverless Workflows * Sysout custom type now supports hardcoded strings (before it was only supporting expressions) For more details head to the complete . All artifacts are available now: * Kogito runtime artifacts are available on Maven Central. * Kogito examples can be found . * Kogito images are available on . * Kogito operator is available in the in OpenShift and Kubernetes. * Kogito tooling 0.25.0 artifacts are available at the . A detailed changelog for 1.31.0 can be found in . New to Kogito? Check out our website . Click the "Get Started" button. The post appeared first on .</content><dc:creator>Cristiano Nicolai</dc:creator></entry><entry><title type="html">Revised edition of WildFly books now available!</title><link rel="alternate" href="http://www.mastertheboss.com/articles/news/revised-edition-of-wildfly-books-now-available/" /><author><name>F.Marchioni</name></author><id>http://www.mastertheboss.com/articles/news/revised-edition-of-wildfly-books-now-available/</id><updated>2022-12-10T11:59:16Z</updated><content type="html">Fresh take on WildFly Administration Guide and Practical Enterprise Application development. Both books are now Jakarta EE 10 ready! WildFly 27 has just been released featuring lots of new features and Compatibility Certification for Jakarta EE 10. Im thrilled to announce that the books WildFly Administration Guide and Practical Enterprise Application development are now on ... The post appeared first on .</content><dc:creator>F.Marchioni</dc:creator></entry><entry><title type="html">New WildFly S2I and Runtime Multi-arch Images</title><link rel="alternate" href="https://wildfly.org//news/2022/12/10/wildfly-s2i-images-rename-multi-archs/" /><author><name>Jean-Franois Denise</name></author><id>https://wildfly.org//news/2022/12/10/wildfly-s2i-images-rename-multi-archs/</id><updated>2022-12-10T00:00:00Z</updated><content type="html">This article provides details on the new S2I and runtime multi-arch images. NEW WILDFLY S2I AND RUNTIME MULTI-ARCH IMAGES These new multi-arch images (linux/arm64 in addition to linux/amd64) have a different naming scheme than the current WildFly images to better handle multiple JDK versions and align with the tag scheme used for the WildFly centos7 docker images (as explained in blog post). Note The previous WildFly images are now deprecated and are no longer updated. The new multi-arch image names are: * Runtime image: quay.io/wildfly/wildfly-runtime:&lt;tag&gt; * S2I builder image: quay.io/wildfly/wildfly-s2i:&lt;tag&gt; This change is described in this . In short, the WildFly image names used to contain the JDK version (e.g: wildfly/wildfly-s2i-jdk11) leading to some lack of flexibility: * An increasing number of new images for each new JDK version. * No ability to identify a pair of images supporting the latest LTS (Long Term Support) JDK. The JDK version has been removed from the image name and moved to the image tag. In addition we have introduced a latest tag that identifies the images supporting the latest LTS JDK. You can identify the exact images version supporting a given JDK version: * quay.io/wildfly/wildfly-runtime:1.0.0-jdk11 used to be quay.io/wildfly/wildfly-runtime-jdk11:1.0.0 * quay.io/wildfly/wildfly-runtime:1.0.0-jdk17 used to be quay.io/wildfly/wildfly-runtime-jdk17:1.0.0 * quay.io/wildfly/wildfly-s2i:1.0.0-jdk11 used to be quay.io/wildfly/wildfly-s2i-jdk11:1.0.0 * quay.io/wildfly/wildfly-s2i:1.0.0-jdk17 used to be quay.io/wildfly/wildfly-s2i-jdk17:1.0.0 You can identify the latest images supporting a given JDK version: * quay.io/wildfly/wildfly-runtime:latest-jdk11 used to be quay.io/wildfly/wildfly-runtime-jdk11:latest * quay.io/wildfly/wildfly-runtime:latest-jdk17 used to be quay.io/wildfly/wildfly-runtime-jdk17:latest * quay.io/wildfly/wildfly-s2i:latest-jdk11 used to be quay.io/wildfly/wildfly-s2i-jdk11:latest * quay.io/wildfly/wildfly-s2i:latest-jdk17 used to be quay.io/wildfly/wildfly-s2i-jdk17:latest You can now identify the latest image supporting the latest LTS JDK version (JDK 17 at the time of this writing): * quay.io/wildfly/wildfly-runtime:latest * quay.io/wildfly/wildfly-s2i:latest Note Relying on this image tag implies that the JDK version will get automatically updated when a new LTS JDK is released and supported by the WildFly images. DEPRECATED SNAPSHOT MULTI-ARCH IMAGES Up to now, we were releasing multi-arch images as preview ones in the quay.io/wildfly-snapshots organization: * quay.io/wildfly-snapshots/wildfly-runtime-jdk11-multi-arch:latest * quay.io/wildfly-snapshots/wildfly-runtime-jdk17-multi-arch:latest * quay.io/wildfly-snapshots/wildfly-s2i-jdk11-multi-arch:latest * quay.io/wildfly-snapshots/wildfly-s2i-jdk17-multi-arch:latest These images are now deprecated and no longer updated. DEPRECATED WILDFLY IMAGES The following single-arch images are now deprecated and are no longer updated: * quay.io/wildfly/wildfly-runtime-jdk11:&lt;tag&gt; * quay.io/wildfly/wildfly-runtime-jdk17:&lt;tag&gt; * quay.io/wildfly/wildfly-s2i-jdk11:&lt;tag&gt; * quay.io/wildfly/wildfly-s2i-jdk17:&lt;tag&gt; NEW OPENSHIFT IMAGE STREAMS The previous image streams (, , , ) have been deprecated. The new image streams are: * WildFly s2i builder: * WildFly runtime: IMPACT ON HELM CHARTS FOR WILDFLY version 2.3.1 is required to use these new images. Helm Chart for WildFly now uses the quay.io/wildfly/wildfly-s2i:latest and quay.io/wildfly/wildfly-runtime:latest (latest LTS JDK) by default, used to be JDK11. If you have already installed the Helm Charts for WildFly, make sure to update your repository to the latest version. This is done by calling: helm repo update USING THE IMAGES The image naming change is transparent when using Helm Charts for WildFly. Usage of these images is covered by WildFly S2I , , wildfly-s2i image and wildfly-runtime image . SUMMARY With the introduction of these new multi-arch images, we are putting in place a long term tagging scheme to better support future JDK versions. You feedback as always is very welcome. Feel free to log these as new . Thank-you! JF Denise</content><dc:creator>Jean-Franois Denise</dc:creator></entry><entry><title>Top Ansible and automation resources of 2022</title><link rel="alternate" href="https://developers.redhat.com/articles/2022/12/09/best-2022-ansible-and-automation" /><author><name>Heiker Medina</name></author><id>2771afe8-efb6-427f-9d01-e358e4970bfe</id><updated>2022-12-09T17:48:43Z</updated><published>2022-12-09T17:48:43Z</published><summary type="html">&lt;p&gt;Developers are increasingly turning to &lt;a href="https://developers.redhat.com/topics/automation"&gt;automated development and deployment processes&lt;/a&gt; to meet the challenge of building cloud-native applications. In the era of cloud computing, your apps must react to &lt;a href="https://developers.redhat.com/topics/event-driven/"&gt;event-driven systems&lt;/a&gt; in scalable and flexible ways. Learn more about how Red Hat Developer readers used Ansible and Helm to make this possible in 2022.&lt;/p&gt; &lt;p&gt;Don't miss the other articles in our Best of 2022 series:&lt;/p&gt; &lt;ul&gt;&lt;li&gt;&lt;a href="https://developers.redhat.com/articles/2022/12/01/top-linux-resources-2022"&gt;Top Linux resources of 2022&lt;/a&gt;&lt;/li&gt; &lt;li&gt;&lt;a href="https://developers.redhat.com/articles/2022/12/06/top-kubernetes-and-openshift-resources-2022"&gt;Top Kubernetes and OpenShift resources of 2022&lt;/a&gt;&lt;/li&gt; &lt;/ul&gt;&lt;h2&gt;API management&lt;/h2&gt; &lt;p&gt;Quarkus has made great progress in the past year, and its &lt;a href="https://developers.redhat.com/articles/2022/02/03/build-rest-api-ground-quarkus-20"&gt;tooling and overall usability have improved significantly&lt;/a&gt;. It is still fast and lightweight, and if you are looking for a modern Java framework for your next project, then Quarkus should be at the top of your list. If you're building an API, &lt;a href="https://developers.redhat.com/articles/2022/10/06/how-make-your-apis-more-discoverable"&gt;follow this guide by Vamsi Ravula and Hugo Guerrero&lt;/a&gt;. It's important to think about how people will find the API before you build it so that you don't have to come up with something on the fly.&lt;/p&gt; &lt;p&gt;To make sure your API is secure, use these &lt;a href="https://developers.redhat.com/articles/2022/10/20/10-essentials-mitigating-api-security-risks#how_red_hat_secures_apis"&gt;ten solutions and tools to help manage security&lt;/a&gt; throughout each step of the API life cycle.&lt;/p&gt; &lt;p&gt;To develop a successful API program, it is important to provide your developers with a developer portal that they can use to access your APIs. Vamsi Ravula shows you &lt;a href="https://developers.redhat.com/articles/2022/05/05/build-customized-developer-portal-manage-apis"&gt;how Red Hat 3scale API Management can be deployed on Red Hat OpenShift&lt;/a&gt; to provide a customizable developer portal. The procedure in this article shows the power of &lt;a href="https://developers.redhat.com/products/openshift/overview"&gt;Red Hat OpenShift&lt;/a&gt; as an application development platform, and how developers can get access to all of these components from the OpenShift console.&lt;/p&gt; &lt;h2&gt;Helm&lt;/h2&gt; &lt;p&gt;Jose Carvajal Hilario and Charles Moulliard demonstrated &lt;a href="https://developers.redhat.com/articles/2022/10/12/generate-helm-charts-using-dekorate"&gt;three ways that Dekorate simplifies Helm chart generation&lt;/a&gt;: it lets you easily generate Helm charts, it helps you map properties to be set when installing or updating your charts, and it allows you to use profiles.&lt;/p&gt; &lt;p&gt;Rohan Kumar shows you &lt;a href="https://developers.redhat.com/articles/2022/08/01/how-configure-helm-charts-using-jkube-part-2"&gt;how to set up Helm charts using Maven and Gradle plugins&lt;/a&gt;, with configuration options from Eclipse JKube. The article covers XML, Java properties, and resource fragments, finishing up by demonstrating how to configure a Helm registry to store your configuration.&lt;/p&gt; &lt;h2&gt;Ansible&lt;/h2&gt; &lt;p&gt;If you're interested in Ansible for middleware series, you'll want to read Romain Pelisse's article on &lt;a href="https://developers.redhat.com/articles/2022/04/20/deploy-keycloak-single-sign-ansible"&gt;using Ansible to simplify the installation of Keycloak&lt;/a&gt;, an open source identity provider that enables single sign-on functionality for Web applications.&lt;/p&gt; &lt;p&gt;Red Hat Ansible Automation Platform also enables developers to &lt;a href="https://developers.redhat.com/articles/2022/09/07/5-examples-security-automation-ansible"&gt;automate the deployment and configuration of security tools&lt;/a&gt;, including firewalls, IDS/IPSes, SIEMs, PAMs, and EPPs. Jamie Beck and Himanshu Yadav explore five common use cases for automating these technologies.&lt;/p&gt; &lt;p&gt;In Harsha Cherukuri's article, he uses &lt;a href="https://developers.redhat.com/articles/2022/08/17/how-ansible-simplifies-jboss-eap-deployment-azure"&gt;Ansible to create Azure resources&lt;/a&gt;, deploys JBoss EAP using WildFly, and then deploys WildFly on an Azure VM.&lt;/p&gt; &lt;p&gt;Finally, revisit 2022's big Ansible announcement: &lt;a href="https://developers.redhat.com/blog/2022/11/29/whats-new-ansible-automation-platform-23"&gt;Ansible Automation Platform 2.3&lt;/a&gt; makes it easier than ever to automate system configuration, application deployment, and network settings across your entire enterprise via code.&lt;/p&gt; &lt;h2&gt;CI/CD&lt;/h2&gt; &lt;p&gt;In this &lt;a href="https://developers.redhat.com/articles/2022/01/13/developers-guide-cicd-and-gitops-jenkins-pipelines"&gt;tutorial article&lt;/a&gt;, Bob Reselman starts with a brief review of what Jenkins is and what it can do. Then, he explains how to use a Jenkinsfile to create deployments that combine CI/CD and GitOps.&lt;/p&gt; &lt;p&gt;Dotnet build-image is a tool that helps you containerize your .NET applications. You can use it to generate Dockerfiles and containerized images, and you'll discover with Tom Deseyn how to work with this tool in a GitHub workflow to &lt;a href="https://developers.redhat.com/articles/2022/08/01/containerize-net-applications-without-writing-dockerfiles"&gt;create an image from a .NET application and push it to a repository&lt;/a&gt;&lt;/p&gt; &lt;p&gt;Red Hat Developer has put together a collection of our &lt;a href="https://developers.redhat.com/articles/2022/10/20/ultimate-cicd-resource-guide#recent_articles_to_explore_about_ci_cd"&gt;highest-performing articles on CI/CD&lt;/a&gt;. This article will introduce you to all things related to this topic.&lt;/p&gt; &lt;p&gt;In Christian Hernandez's article &lt;a href="https://developers.redhat.com/articles/2022/09/07/how-set-your-gitops-directory-structure"&gt;How to set up your GitOps directory structure&lt;/a&gt;, he discusses how to create repositories and directories in GitOps. Although there is no one answer, these basic best practices can help you see where to start.&lt;/p&gt; &lt;h2&gt;Resources&lt;/h2&gt; &lt;p&gt;Automation helps scale infrastructure, strengthen security, and improve customer experience. In the short e-book &lt;em&gt;An IT executive's guide to automation,&lt;/em&gt; you will discover the &lt;a href="https://developers.redhat.com/e-books/it-executives-guide-automation"&gt;benefits of a long-term transformative automation strategy&lt;/a&gt;. You'll also find out how to automate your infrastructure with Red Hat. Another resource to review is our &lt;a href="https://developers.redhat.com/cheat-sheets/git-cheat-sheet"&gt;basic Git commands cheat sheet&lt;/a&gt; The commands you'll learn more about help you work with files along with repositories and their branches, resolve merge conflicts, and more. You'll also learn how to move content between the remote repository and your local workspace, rebase or merge files between branches, and resolve merge conflicts when they occur.&lt;/p&gt; &lt;h2&gt;Learning paths&lt;/h2&gt; &lt;p&gt;You can simplify your IT tasks by creating a centralized and automated process with Ansible. Review &lt;a href="https://developers.redhat.com/learn/ansible"&gt;Red Hat Developer's Ansible learning path&lt;/a&gt; today!&lt;/p&gt; The post &lt;a href="https://developers.redhat.com/articles/2022/12/09/best-2022-ansible-and-automation" title="Top Ansible and automation resources of 2022"&gt;Top Ansible and automation resources of 2022&lt;/a&gt; appeared first on &lt;a href="https://developers.redhat.com/blog" title="Red Hat Developer"&gt;Red Hat Developer&lt;/a&gt;. &lt;br /&gt;&lt;br /&gt;</summary><dc:creator>Heiker Medina</dc:creator><dc:date>2022-12-09T17:48:43Z</dc:date></entry><entry><title type="html">Using JBeret With Quarkus</title><link rel="alternate" href="https://jberet.github.io/jberet-quarkus/" /><author><name></name></author><id>https://jberet.github.io/jberet-quarkus/</id><updated>2022-12-09T00:00:00Z</updated><dc:creator></dc:creator></entry><entry><title type="html">Integrate Red Hat Process Automation Manager with Springboot</title><link rel="alternate" href="https://blog.kie.org/2022/12/integrate-red-hat-process-automation-manager-with-springboot.html" /><author><name>Archana Krishnan</name></author><id>https://blog.kie.org/2022/12/integrate-red-hat-process-automation-manager-with-springboot.html</id><updated>2022-12-08T23:16:25Z</updated><content type="html">We worked on a request to migrate RHPAM/EAP applications to RHPAM/Springboot. The following steps were adopted to help the client move into RHPAM/Springboot containers. ENVIRONMENT: * Red Hat Process Automation Manager (7.12.1) connected to PostgreSQL * Red Hat AMQ 7.10 * Red Hat Openshift Container Platform 4.10 DATABASE CONFIGURATION: There are differences in the sequence configured for RHPAM/EAP application and RHPAM/Springboot applications. Please run the below script to update sequence: alter sequence BAM_TASK_ID_SEQ increment by 50; alter sequence CASE_ID_INFO_ID_SEQ increment by 50; alter sequence CONTEXT_MAPPING_INFO_ID_SEQ increment by 50; alter sequence CORRELATION_KEY_ID_SEQ increment by 50; alter sequence CORRELATION_PROP_ID_SEQ increment by 50; alter sequence ERROR_INFO_ID_SEQ increment by 50; alter sequence PROCESS_INSTANCE_INFO_ID_SEQ increment by 50; alter sequence REQUEST_INFO_ID_SEQ increment by 50; alter sequence SESSIONINFO_ID_SEQ increment by 50; alter sequence TASK_DEF_ID_SEQ increment by 50; alter sequence TASK_EVENT_ID_SEQ increment by 50; alter sequence WORKITEMINFO_ID_SEQ increment by 50; Update application.properties with the following properties to connect to PostgreSQL: spring.datasource.username=jbpm spring.datasource.password=jbpm spring.datasource.url=jdbc:postgresql://localhost:5432/jbpm spring.datasource.driver-class-name=org.postgresql.Driver spring.jpa.properties.hibernate.dialect=org.hibernate.dialect.PostgreSQLDialect spring.jpa.hibernate.ddl-auto=validate spring.jpa.hibernate.naming.physical-strategy=org.hibernate.boot.model.naming.PhysicalNamingStrategyStandardImpl PersistenceException is expected if the sequence is not updated and RHPAM/Springboot application tries to connect to the database: org.springframework.beans.factory.BeanCreationException: Error creating bean with name 'entityManagerFactory' defined in class path resource [org/jbpm/springboot/autoconfigure/JBPMAutoConfiguration.class]: Invocation of init method failed; nested exception is javax.persistence.PersistenceException: [PersistenceUnit: org.jbpm.domain] Unable to build Hibernate SessionFactory; nested exception is org.hibernate.MappingException: Could not instantiate id generator [entity-name=org.jbpm.services.task.impl.model.TaskDefImpl] Caused by: org.hibernate.MappingException: The increment size of the [TASK_DEF_ID_SEQ] sequence is set to [50] in the entity mapping while the associated database sequence increment size is [1]. AMQ CONFIGURATION: Update the application.properties with the following parameters to connect to AMQ: amqphub.amqp10jms.remoteUrl=amqp://localhost:5672 amqphub.amqp10jms.username=admin amqphub.amqp10jms.password=admin jms.queue.destination=request-queue KIE SERVER CONFIGURATION: Update application.properties with the following properties: server.address=0.0.0.0 server.port=8090 cxf.path=/rest #kie server config kieserver.serverId=sp-sb-kie-server kieserver.serverName=sp-sb-kie-server kieserver.location=http://localhost:8090/rest/server kieserver.classPathContainer=true #kie server capabilities kieserver.drools.enabled=true kieserver.dmn.enabled=true kieserver.jbpm.enabled=true kieserver.jbpmui.enabled=true kieserver.casemgmt.enabled=true #kieserver.prometheus.enabled=true kieserver.swagger.enabled=true kieserver.deployments[&lt;n&gt;].containerId=&lt;container&gt; kieserver.deployments[&lt;n&gt;].alias=&lt;alias&gt; kieserver.deployments[&lt;n&gt;].artifactId=&lt;artifact&gt; kieserver.deployments[&lt;n&gt;].groupId=&lt;group&gt; kieserver.deployments[&lt;n&gt;].version=&lt;version&gt; #jbpm configuration jbpm.executor.enabled=true jbpm.executor.retries=5 jbpm.executor.interval=3 jbpm.executor.threadPoolSize=10 jbpm.executor.timeUnit=SECONDS #transaction manager configuration spring.jta.narayana.transaction-manager-id=1 #banner spring.banner.location=classpath:banner.txt narayana.transaction-manager-id=1 narayana.default-timeout=120 narayana.dbcp.enabled=true #logging logging.level.org.kie: INFO logging.level.org.jbpm: ERROR QUARTZ TIMER CONFIGURATION: DDL script to include DB configuration for quartz timer: CREATE TABLE qrtz_job_details ( SCHED_NAME VARCHAR(120) NOT NULL, JOB_NAME VARCHAR(200) NOT NULL, JOB_GROUP VARCHAR(200) NOT NULL, DESCRIPTION VARCHAR(250) NULL, JOB_CLASS_NAME VARCHAR(250) NOT NULL, IS_DURABLE BOOL NOT NULL, IS_NONCONCURRENT BOOL NOT NULL, IS_UPDATE_DATA BOOL NOT NULL, REQUESTS_RECOVERY BOOL NOT NULL, JOB_DATA BYTEA NULL, PRIMARY KEY (SCHED_NAME,JOB_NAME,JOB_GROUP) ); CREATE TABLE qrtz_triggers ( SCHED_NAME VARCHAR(120) NOT NULL, TRIGGER_NAME VARCHAR(200) NOT NULL, TRIGGER_GROUP VARCHAR(200) NOT NULL, JOB_NAME VARCHAR(200) NOT NULL, JOB_GROUP VARCHAR(200) NOT NULL, DESCRIPTION VARCHAR(250) NULL, NEXT_FIRE_TIME BIGINT NULL, PREV_FIRE_TIME BIGINT NULL, PRIORITY INTEGER NULL, TRIGGER_STATE VARCHAR(16) NOT NULL, TRIGGER_TYPE VARCHAR(8) NOT NULL, START_TIME BIGINT NOT NULL, END_TIME BIGINT NULL, CALENDAR_NAME VARCHAR(200) NULL, MISFIRE_INSTR SMALLINT NULL, JOB_DATA BYTEA NULL, PRIMARY KEY (SCHED_NAME,TRIGGER_NAME,TRIGGER_GROUP), FOREIGN KEY (SCHED_NAME,JOB_NAME,JOB_GROUP) REFERENCES QRTZ_JOB_DETAILS(SCHED_NAME,JOB_NAME,JOB_GROUP) ); CREATE TABLE qrtz_simple_triggers ( SCHED_NAME VARCHAR(120) NOT NULL, TRIGGER_NAME VARCHAR(200) NOT NULL, TRIGGER_GROUP VARCHAR(200) NOT NULL, REPEAT_COUNT BIGINT NOT NULL, REPEAT_INTERVAL BIGINT NOT NULL, TIMES_TRIGGERED BIGINT NOT NULL, PRIMARY KEY (SCHED_NAME,TRIGGER_NAME,TRIGGER_GROUP), FOREIGN KEY (SCHED_NAME,TRIGGER_NAME,TRIGGER_GROUP) REFERENCES QRTZ_TRIGGERS(SCHED_NAME,TRIGGER_NAME,TRIGGER_GROUP) ); CREATE TABLE qrtz_cron_triggers ( SCHED_NAME VARCHAR(120) NOT NULL, TRIGGER_NAME VARCHAR(200) NOT NULL, TRIGGER_GROUP VARCHAR(200) NOT NULL, CRON_EXPRESSION VARCHAR(120) NOT NULL, TIME_ZONE_ID VARCHAR(80), PRIMARY KEY (SCHED_NAME,TRIGGER_NAME,TRIGGER_GROUP), FOREIGN KEY (SCHED_NAME,TRIGGER_NAME,TRIGGER_GROUP) REFERENCES QRTZ_TRIGGERS(SCHED_NAME,TRIGGER_NAME,TRIGGER_GROUP) ); CREATE TABLE qrtz_simprop_triggers ( SCHED_NAME VARCHAR(120) NOT NULL, TRIGGER_NAME VARCHAR(200) NOT NULL, TRIGGER_GROUP VARCHAR(200) NOT NULL, STR_PROP_1 VARCHAR(512) NULL, STR_PROP_2 VARCHAR(512) NULL, STR_PROP_3 VARCHAR(512) NULL, INT_PROP_1 INT NULL, INT_PROP_2 INT NULL, LONG_PROP_1 BIGINT NULL, LONG_PROP_2 BIGINT NULL, DEC_PROP_1 NUMERIC(13,4) NULL, DEC_PROP_2 NUMERIC(13,4) NULL, BOOL_PROP_1 BOOL NULL, BOOL_PROP_2 BOOL NULL, PRIMARY KEY (SCHED_NAME,TRIGGER_NAME,TRIGGER_GROUP), FOREIGN KEY (SCHED_NAME,TRIGGER_NAME,TRIGGER_GROUP) REFERENCES QRTZ_TRIGGERS(SCHED_NAME,TRIGGER_NAME,TRIGGER_GROUP) ); CREATE TABLE qrtz_blob_triggers ( SCHED_NAME VARCHAR(120) NOT NULL, TRIGGER_NAME VARCHAR(200) NOT NULL, TRIGGER_GROUP VARCHAR(200) NOT NULL, BLOB_DATA BYTEA NULL, PRIMARY KEY (SCHED_NAME,TRIGGER_NAME,TRIGGER_GROUP), FOREIGN KEY (SCHED_NAME,TRIGGER_NAME,TRIGGER_GROUP) REFERENCES QRTZ_TRIGGERS(SCHED_NAME,TRIGGER_NAME,TRIGGER_GROUP) ); CREATE TABLE qrtz_calendars ( SCHED_NAME VARCHAR(120) NOT NULL, CALENDAR_NAME VARCHAR(200) NOT NULL, CALENDAR BYTEA NOT NULL, PRIMARY KEY (SCHED_NAME,CALENDAR_NAME) ); CREATE TABLE qrtz_paused_trigger_grps ( SCHED_NAME VARCHAR(120) NOT NULL, TRIGGER_GROUP VARCHAR(200) NOT NULL, PRIMARY KEY (SCHED_NAME,TRIGGER_GROUP) ); CREATE TABLE qrtz_fired_triggers ( SCHED_NAME VARCHAR(120) NOT NULL, ENTRY_ID VARCHAR(95) NOT NULL, TRIGGER_NAME VARCHAR(200) NOT NULL, TRIGGER_GROUP VARCHAR(200) NOT NULL, INSTANCE_NAME VARCHAR(200) NOT NULL, FIRED_TIME BIGINT NOT NULL, SCHED_TIME BIGINT NOT NULL, PRIORITY INTEGER NOT NULL, STATE VARCHAR(16) NOT NULL, JOB_NAME VARCHAR(200) NULL, JOB_GROUP VARCHAR(200) NULL, IS_NONCONCURRENT BOOL NULL, REQUESTS_RECOVERY BOOL NULL, PRIMARY KEY (SCHED_NAME,ENTRY_ID) ); CREATE TABLE qrtz_scheduler_state ( SCHED_NAME VARCHAR(120) NOT NULL, INSTANCE_NAME VARCHAR(200) NOT NULL, LAST_CHECKIN_TIME BIGINT NOT NULL, CHECKIN_INTERVAL BIGINT NOT NULL, PRIMARY KEY (SCHED_NAME,INSTANCE_NAME) ); CREATE TABLE qrtz_locks ( SCHED_NAME VARCHAR(120) NOT NULL, LOCK_NAME VARCHAR(40) NOT NULL, PRIMARY KEY (SCHED_NAME,LOCK_NAME) ); create index idx_qrtz_j_req_recovery on qrtz_job_details(SCHED_NAME,REQUESTS_RECOVERY); create index idx_qrtz_j_grp on qrtz_job_details(SCHED_NAME,JOB_GROUP); create index idx_qrtz_t_j on qrtz_triggers(SCHED_NAME,JOB_NAME,JOB_GROUP); create index idx_qrtz_t_jg on qrtz_triggers(SCHED_NAME,JOB_GROUP); create index idx_qrtz_t_c on qrtz_triggers(SCHED_NAME,CALENDAR_NAME); create index idx_qrtz_t_g on qrtz_triggers(SCHED_NAME,TRIGGER_GROUP); create index idx_qrtz_t_state on qrtz_triggers(SCHED_NAME,TRIGGER_STATE); create index idx_qrtz_t_n_state on qrtz_triggers(SCHED_NAME,TRIGGER_NAME,TRIGGER_GROUP,TRIGGER_STATE); create index idx_qrtz_t_n_g_state on qrtz_triggers(SCHED_NAME,TRIGGER_GROUP,TRIGGER_STATE); create index idx_qrtz_t_next_fire_time on qrtz_triggers(SCHED_NAME,NEXT_FIRE_TIME); create index idx_qrtz_t_nft_st on qrtz_triggers(SCHED_NAME,TRIGGER_STATE,NEXT_FIRE_TIME); create index idx_qrtz_t_nft_misfire on qrtz_triggers(SCHED_NAME,MISFIRE_INSTR,NEXT_FIRE_TIME); create index idx_qrtz_t_nft_st_misfire on qrtz_triggers(SCHED_NAME,MISFIRE_INSTR,NEXT_FIRE_TIME,TRIGGER_STATE); create index idx_qrtz_t_nft_st_misfire_grp on qrtz_triggers(SCHED_NAME,MISFIRE_INSTR,NEXT_FIRE_TIME,TRIGGER_GROUP,TRIGGER_STATE); create index idx_qrtz_ft_trig_inst_name on qrtz_fired_triggers(SCHED_NAME,INSTANCE_NAME); create index idx_qrtz_ft_inst_job_req_rcvry on qrtz_fired_triggers(SCHED_NAME,INSTANCE_NAME,REQUESTS_RECOVERY); create index idx_qrtz_ft_j_g on qrtz_fired_triggers(SCHED_NAME,JOB_NAME,JOB_GROUP); create index idx_qrtz_ft_jg on qrtz_fired_triggers(SCHED_NAME,JOB_GROUP); create index idx_qrtz_ft_t_g on qrtz_fired_triggers(SCHED_NAME,TRIGGER_NAME,TRIGGER_GROUP); create index idx_qrtz_ft_tg on qrtz_fired_triggers(SCHED_NAME,TRIGGER_GROUP); Add the quartz properties file at src/main/resources/quartz.properties: #============================================================================ # Configure Main Scheduler Properties #============================================================================ org.quartz.scheduler.instanceName = SpringBootScheduler org.quartz.scheduler.instanceId = AUTO org.quartz.scheduler.skipUpdateCheck=true org.quartz.scheduler.idleWaitTime=1000 #============================================================================ # Configure ThreadPool #============================================================================ org.quartz.threadPool.class = org.quartz.simpl.SimpleThreadPool org.quartz.threadPool.threadCount = 5 org.quartz.threadPool.threadPriority = 5 #============================================================================ # Configure JobStore #============================================================================ org.quartz.jobStore.misfireThreshold = 60000 org.quartz.jobStore.class=org.quartz.impl.jdbcjobstore.JobStoreCMT org.quartz.jobStore.driverDelegateClass=org.quartz.impl.jdbcjobstore.PostgreSQLDelegate org.quartz.jobStore.useProperties=false org.quartz.jobStore.dataSource=myDS org.quartz.jobStore.nonManagedTXDataSource=notManagedDS org.quartz.jobStore.tablePrefix=QRTZ_ org.quartz.jobStore.isClustered=true org.quartz.jobStore.clusterCheckinInterval = 5000 #============================================================================ # Configure Datasources #============================================================================ org.quartz.dataSource.myDS.connectionProvider.class=org.jbpm.springboot.quartz.SpringConnectionProvider org.quartz.dataSource.myDS.dataSourceName=quartzDataSource org.quartz.dataSource.notManagedDS.connectionProvider.class=org.jbpm.springboot.quartz.SpringConnectionProvider org.quartz.dataSource.notManagedDS.dataSourceName=quartzNotManagedDataSource Update the application.properties: jbpm.quartz.enabled=true jbpm.quartz.configuration=quartz.properties STEPS TO DEPLOY THE APPLICATION TO OCP 4.10 1. Create ocp-image directory outside the business-application project with the following structure: ocp-image |--/root |--/opt |-- /spring-service 2. Copy JAR file to root/opt/spring-service. For example: cd ../business-application cp target/business-application-1.0-SNAPSHOT.jar ../ocp-image/root/opt/spring-service/ 3. Create a Dockerfile with the following content in the directory /ocp-image/ FROM registry.access.redhat.com/ubi8/openjdk-11:latest COPY root / EXPOSE 8090 WORKDIR /opt/spring-service/ RUN chown -R jboss:root /opt/spring-service/ &amp;amp;&amp; chmod 777 /opt/spring-service/ CMD ["sh","-c", "java ${JAVA_OPTIONS} -Dorg.kie.server.mode=PRODUCTION -jar /opt/spring-service/&lt;FILENAME&gt;.jar"] 4. Build and deploy application to OCP 4.10 oc new-build --binary --strategy=docker --name kie-springboot oc start-build kie-springboot --from-dir=. --follow oc new-app kie-springboot oc expose service/kie-springboot --port=8090 The post appeared first on .</content><dc:creator>Archana Krishnan</dc:creator></entry></feed>
